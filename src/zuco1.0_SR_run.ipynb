{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32bf103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader for ZuCo 1.0 data set (SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e65874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class ZucoDataLoader:\n",
    "    def __init__(self, data_dir='../zuco_data/zuco1.0/task1-SR/Matlab files'):\n",
    "        self.data_dir = data_dir\n",
    "        self.subject_files = self._get_subject_files()\n",
    "        \n",
    "    def _get_subject_files(self):\n",
    "        subject_files = {}\n",
    "        for file_name in os.listdir(self.data_dir):\n",
    "            if file_name.endswith(\".mat\"):\n",
    "                subject_id = file_name.split('.')[0]\n",
    "                subject_files[subject_id] = os.path.join(self.data_dir, file_name)\n",
    "        return subject_files\n",
    "    \n",
    "    def get_subject_ids(self):\n",
    "        return list(self.subject_files.keys())\n",
    "    \n",
    "    def load_subject_data(self, subject_id):\n",
    "        file_path = self.subject_files[subject_id]\n",
    "        print(f\"Loading data from {file_path}\")\n",
    "        data = loadmat(file_path, squeeze_me=True, struct_as_record=False)\n",
    "        return data\n",
    "    \n",
    "    def extract_word_level_data(self, subject_id):\n",
    "        \"\"\"Extract word-level EEG data with sentence context\"\"\"\n",
    "        data = self.load_subject_data(subject_id)\n",
    "        sentences = data['sentenceData']\n",
    "        \n",
    "        # Store word-level data\n",
    "        word_data = []\n",
    "        \n",
    "        for sent_idx, sentence in enumerate(sentences):\n",
    "            try:\n",
    "                # Check if words is iterable\n",
    "                if not hasattr(sentence, 'word'):\n",
    "                    print(f\"Sentence {sent_idx} has no word attribute\")\n",
    "                    continue\n",
    "                    \n",
    "                words = sentence.word\n",
    "                \n",
    "                # Handle case where words is not iterable (e.g., a float)\n",
    "                if not hasattr(words, '__iter__'):\n",
    "                    print(f\"Sentence {sent_idx} words is not iterable: {type(words)}\")\n",
    "                    continue\n",
    "                    \n",
    "                sentence_text = sentence.content if hasattr(sentence, 'content') else \"\"\n",
    "                \n",
    "                for word_idx, word in enumerate(words):\n",
    "                    # Extract EEG features\n",
    "                    eeg_features = {}\n",
    "                    word_text = word.content if hasattr(word, 'content') else \"\"\n",
    "                    \n",
    "                    # Extract each frequency band\n",
    "                    for feature in ['FFD', 'TRT', 'GD', 'GPT']:\n",
    "                        for band in ['_t1', '_t2', '_a1', '_a2', '_b1', '_b2', '_g1', '_g2']:\n",
    "                            feature_name = feature + band\n",
    "                            if hasattr(word, feature_name):\n",
    "                                eeg_features[feature_name] = getattr(word, feature_name)\n",
    "                    \n",
    "                    word_data.append({\n",
    "                        'word': word_text,\n",
    "                        'word_idx': word_idx,\n",
    "                        'sentence_id': sent_idx,\n",
    "                        'sentence': sentence_text,\n",
    "                        'eeg_features': eeg_features\n",
    "                    })\n",
    "            except (AttributeError, IndexError, TypeError) as e:\n",
    "                print(f\"Error processing sentence {sent_idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return word_data\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self, model_name='gpt2-medium'):\n",
    "        \"\"\"Initialize with TransformerLens\"\"\"\n",
    "        print(f\"Loading model {model_name}...\")\n",
    "        self.model = HookedTransformer.from_pretrained(model_name)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def extract_embeddings_sliding_window(self, word_data):\n",
    "        \"\"\"\n",
    "        Generate contextual embeddings using sliding window approach (Goldstein method)\n",
    "        \"\"\"\n",
    "        # Group by sentence\n",
    "        sentences = {}\n",
    "        for word in word_data:\n",
    "            sent_id = word['sentence_id']\n",
    "            if sent_id not in sentences:\n",
    "                sentences[sent_id] = {\n",
    "                    'text': word['sentence'],\n",
    "                    'words': []\n",
    "                }\n",
    "            sentences[sent_id]['words'].append(word)\n",
    "        \n",
    "        # Process each sentence\n",
    "        embeddings = []\n",
    "        \n",
    "        for sent_id, sent_info in tqdm(sentences.items(), desc=\"Extracting embeddings\"):\n",
    "            sent_text = sent_info['text']\n",
    "            words = sent_info['words']\n",
    "            \n",
    "            # Sort words by position\n",
    "            words.sort(key=lambda x: x['word_idx'])\n",
    "            \n",
    "            # Process each word with its preceding context\n",
    "            for i, word in enumerate(words):\n",
    "                # Build context window (all words up to and including current)\n",
    "                word_tokens = [w['word'] for w in words[:i+1]]\n",
    "                context = \" \".join(word_tokens)\n",
    "                \n",
    "                # Get activations for this context\n",
    "                _, cache = self.model.run_with_cache(context)\n",
    "                \n",
    "                # Extract final layer activation for last token\n",
    "                # This follows Goldstein's methodology\n",
    "                final_layer_activations = cache['blocks.23.hook_resid_post'][0]\n",
    "                word_embedding = final_layer_activations[-1].detach().cpu().numpy()\n",
    "                \n",
    "                embeddings.append({\n",
    "                    'word': word['word'],\n",
    "                    'sentence_id': sent_id,\n",
    "                    'word_idx': word['word_idx'],\n",
    "                    'embedding': word_embedding,\n",
    "                    'eeg_features': word['eeg_features']\n",
    "                })\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "class BrainEmbeddingMapper:\n",
    "    def __init__(self):\n",
    "        \"\"\"Linear mapper between embeddings and EEG\"\"\"\n",
    "        self.models = {}\n",
    "    \n",
    "    def train_mapper(self, embeddings, feature_name='FFD_t1', n_splits=5):\n",
    "        \"\"\"Train a linear mapping between embeddings and EEG features\"\"\"\n",
    "        # First, check dimensions of the feature\n",
    "        sample_shapes = {}\n",
    "        for item in embeddings:\n",
    "            if feature_name in item['eeg_features']:\n",
    "                feature = item['eeg_features'][feature_name]\n",
    "                if hasattr(feature, 'shape'):\n",
    "                    shape = feature.shape\n",
    "                    if shape not in sample_shapes:\n",
    "                        sample_shapes[shape] = 0\n",
    "                    sample_shapes[shape] += 1\n",
    "        \n",
    "        print(f\"Found {len(sample_shapes)} different shapes for {feature_name}\")\n",
    "        for shape, count in sample_shapes.items():\n",
    "            print(f\"  Shape {shape}: {count} samples\")\n",
    "        \n",
    "        # Choose most common shape with non-zero dimensions\n",
    "        valid_shapes = {shape: count for shape, count in sample_shapes.items() \n",
    "                    if shape and shape[0] > 0}\n",
    "        \n",
    "        if not valid_shapes:\n",
    "            print(f\"No valid shapes found for feature {feature_name}\")\n",
    "            return None\n",
    "        \n",
    "        target_shape = max(valid_shapes.items(), key=lambda x: x[1])[0]\n",
    "        print(f\"Using shape {target_shape} for training\")\n",
    "        \n",
    "        # Filter to samples with consistent dimensions\n",
    "        valid_embeddings = []\n",
    "        valid_features = []\n",
    "        \n",
    "        for item in embeddings:\n",
    "            if feature_name in item['eeg_features']:\n",
    "                feature = item['eeg_features'][feature_name]\n",
    "                if hasattr(feature, 'shape') and feature.shape == target_shape:\n",
    "                    if not np.isnan(feature).any():\n",
    "                        valid_embeddings.append(item['embedding'])\n",
    "                        valid_features.append(feature)\n",
    "        \n",
    "        if len(valid_embeddings) < 10:  # Minimum samples for training\n",
    "            print(f\"Not enough valid samples after filtering\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Training with {len(valid_embeddings)} samples\")\n",
    "        \n",
    "        # Add regularization to handle ill-conditioned matrices\n",
    "        alpha = 10.0  # Increase regularization strength\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(valid_embeddings)\n",
    "        y = np.array(valid_features)\n",
    "        \n",
    "        # Cross-validation\n",
    "        kf = KFold(n_splits=min(n_splits, len(X)), shuffle=True, random_state=42)\n",
    "        results = []\n",
    "        \n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            # Train model\n",
    "            model = Ridge(alpha=alpha)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Predict\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate correlation for each electrode\n",
    "            correlations = []\n",
    "            for i in range(y_test.shape[1]):\n",
    "                if np.std(y_test[:, i]) > 0 and np.std(y_pred[:, i]) > 0:\n",
    "                    corr = np.corrcoef(y_test[:, i], y_pred[:, i])[0, 1]\n",
    "                    correlations.append(corr)\n",
    "            \n",
    "            results.append({\n",
    "                'correlations': correlations,\n",
    "                'mean_correlation': np.mean(correlations)\n",
    "            })\n",
    "        \n",
    "        self.models[feature_name] = {\n",
    "            'model': model,\n",
    "            'results': results\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def train_multifeature_mapper(self, embeddings, features=None, n_splits=5):\n",
    "        \"\"\"Train a linear mapping with multiple features at once\"\"\"\n",
    "        # Get all available features if none specified\n",
    "        if not features:\n",
    "            all_features = set()\n",
    "            for item in embeddings:\n",
    "                all_features.update(item['eeg_features'].keys())\n",
    "            features = sorted(list(all_features))\n",
    "        \n",
    "        print(f\"Training with {len(features)} features\")\n",
    "        \n",
    "        # Find most common electrode count across features\n",
    "        feature_shapes = {}\n",
    "        for feature in features:\n",
    "            shapes = {}\n",
    "            for item in embeddings:\n",
    "                if feature in item['eeg_features']:\n",
    "                    arr = item['eeg_features'][feature]\n",
    "                    if hasattr(arr, 'shape') and len(arr.shape) > 0:\n",
    "                        shape = arr.shape\n",
    "                        if shape not in shapes:\n",
    "                            shapes[shape] = 0\n",
    "                        shapes[shape] += 1\n",
    "            \n",
    "            if shapes:\n",
    "                feature_shapes[feature] = max(shapes.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        if not feature_shapes:\n",
    "            print(\"No valid features found\")\n",
    "            return None\n",
    "        \n",
    "        # Filter to features with same electrode count\n",
    "        valid_features = []\n",
    "        target_shape = (105,)  # Standard electrode count\n",
    "        \n",
    "        for feature, shape in feature_shapes.items():\n",
    "            if shape == target_shape:\n",
    "                valid_features.append(feature)\n",
    "        \n",
    "        if not valid_features:\n",
    "            print(\"No features with consistent electrode count\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Using {len(valid_features)} features with {target_shape[0]} electrodes\")\n",
    "        \n",
    "        # Collect valid samples\n",
    "        valid_data = []\n",
    "        \n",
    "        for item in embeddings:\n",
    "            sample = {\n",
    "                'embedding': item['embedding'],\n",
    "                'targets': {}\n",
    "            }\n",
    "            \n",
    "            has_valid_data = False\n",
    "            for feature in valid_features:\n",
    "                if feature in item['eeg_features']:\n",
    "                    arr = item['eeg_features'][feature]\n",
    "                    if hasattr(arr, 'shape') and arr.shape == target_shape:\n",
    "                        if not np.isnan(arr).any():\n",
    "                            sample['targets'][feature] = arr\n",
    "                            has_valid_data = True\n",
    "            \n",
    "            if has_valid_data:\n",
    "                valid_data.append(sample)\n",
    "        \n",
    "        print(f\"Found {len(valid_data)} samples with valid data\")\n",
    "        \n",
    "        if len(valid_data) < 100:\n",
    "            print(\"Not enough valid samples for training\")\n",
    "            return None\n",
    "        \n",
    "        # Create model for each feature\n",
    "        results = {}\n",
    "        \n",
    "        for feature in valid_features:\n",
    "            # Get samples with this feature\n",
    "            feature_samples = []\n",
    "            feature_targets = []\n",
    "            \n",
    "            for sample in valid_data:\n",
    "                if feature in sample['targets']:\n",
    "                    feature_samples.append(sample['embedding'])\n",
    "                    feature_targets.append(sample['targets'][feature])\n",
    "            \n",
    "            if len(feature_samples) < 100:\n",
    "                print(f\"Skipping feature {feature}: not enough samples\")\n",
    "                continue\n",
    "            \n",
    "            X = np.array(feature_samples)\n",
    "            y = np.array(feature_targets)\n",
    "            \n",
    "            print(f\"Training model for {feature} with {len(X)} samples\")\n",
    "            \n",
    "            # Cross-validation\n",
    "            kf = KFold(n_splits=min(n_splits, len(X)), shuffle=True, random_state=42)\n",
    "            feature_results = []\n",
    "            \n",
    "            for train_idx, test_idx in kf.split(X):\n",
    "                X_train, X_test = X[train_idx], X[test_idx]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "                \n",
    "                # Train model with increased regularization\n",
    "                model = Ridge(alpha=50.0)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # Predict\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # Calculate correlation for each electrode\n",
    "                correlations = []\n",
    "                for i in range(y_test.shape[1]):\n",
    "                    if np.std(y_test[:, i]) > 0 and np.std(y_pred[:, i]) > 0:\n",
    "                        corr = np.corrcoef(y_test[:, i], y_pred[:, i])[0, 1]\n",
    "                        correlations.append(corr)\n",
    "                \n",
    "                feature_results.append({\n",
    "                    'correlations': correlations,\n",
    "                    'mean_correlation': np.mean(correlations)\n",
    "                })\n",
    "            \n",
    "            results[feature] = {\n",
    "                'model': model,\n",
    "                'results': feature_results\n",
    "            }\n",
    "        \n",
    "        # Store models\n",
    "        self.models.update(results)\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "    def train_all_features(self, embeddings, n_splits=5):\n",
    "        \"\"\"Train linear mappings for all available EEG features\"\"\"\n",
    "        # Find all features that appear in the data\n",
    "        all_features = set()\n",
    "        for item in embeddings:\n",
    "            all_features.update(item['eeg_features'].keys())\n",
    "        \n",
    "        print(f\"Found {len(all_features)} features in the data\")\n",
    "        \n",
    "        # Train a model for each feature\n",
    "        results_by_feature = {}\n",
    "        \n",
    "        for feature_name in all_features:\n",
    "            print(f\"\\nTraining model for {feature_name}\")\n",
    "            results = self.train_mapper(embeddings, feature_name=feature_name, n_splits=n_splits)\n",
    "            \n",
    "            if results:\n",
    "                mean_corr = np.mean([fold['mean_correlation'] for fold in results])\n",
    "                print(f\"Mean correlation: {mean_corr:.4f}\")\n",
    "                results_by_feature[feature_name] = results\n",
    "        \n",
    "        return results_by_feature\n",
    "    \n",
    "    \n",
    "    def extract_steering_vector(self, feature_name='FFD_t1', method='weighted', threshold=0.1):\n",
    "        \"\"\"\n",
    "        Extract a steering vector using different methods:\n",
    "        - 'weighted': Weight electrodes by correlation strength\n",
    "        - 'top_n': Use only top N electrodes \n",
    "        - 'threshold': Use electrodes with correlation above threshold\n",
    "        \"\"\"\n",
    "        if feature_name not in self.models:\n",
    "            print(f\"No model trained for feature {feature_name}\")\n",
    "            return None\n",
    "            \n",
    "        feature_data = self.models[feature_name]\n",
    "        \n",
    "        # Handle both single-feature and multi-feature formats\n",
    "        if isinstance(feature_data, dict) and 'model' in feature_data:\n",
    "            model = feature_data['model']\n",
    "            results = feature_data['results']\n",
    "        else:\n",
    "            model = feature_data  # Original format\n",
    "            results = self.models[feature_name]['results']\n",
    "        \n",
    "        weights = model.coef_.T  # [embedding_dim, n_electrodes]\n",
    "        \n",
    "        # Calculate correlation strength per electrode\n",
    "        correlation_means = []\n",
    "        for result in results:\n",
    "            correlation_means.append(np.array(result['correlations']))\n",
    "        electrode_correlations = np.mean(np.stack(correlation_means), axis=0)\n",
    "        \n",
    "        # Select electrodes based on method\n",
    "        if method == 'weighted':\n",
    "            # Weight each electrode by its correlation strength\n",
    "            electrode_weights = np.abs(electrode_correlations)\n",
    "            electrode_weights = electrode_weights / np.sum(electrode_weights)\n",
    "            steering_vector = np.zeros(weights.shape[0])\n",
    "            \n",
    "            for i, weight in enumerate(electrode_weights):\n",
    "                if not np.isnan(weight):\n",
    "                    steering_vector += weight * weights[:, i]\n",
    "                    \n",
    "        elif method == 'top_n':\n",
    "            n_electrodes = 10  # Default to top 10\n",
    "            # Get top N electrodes by absolute correlation\n",
    "            top_indices = np.argsort(np.abs(electrode_correlations))[-n_electrodes:]\n",
    "            steering_vector = np.mean(weights[:, top_indices], axis=1)\n",
    "            \n",
    "        elif method == 'threshold':\n",
    "            # Use electrodes above correlation threshold\n",
    "            mask = np.abs(electrode_correlations) > threshold\n",
    "            if not np.any(mask):\n",
    "                print(f\"No electrodes above threshold {threshold}\")\n",
    "                return None\n",
    "            steering_vector = np.mean(weights[:, mask], axis=1)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "        # Normalize\n",
    "        steering_vector = steering_vector / np.linalg.norm(steering_vector)\n",
    "        return steering_vector  \n",
    "    \n",
    "    def extract_combined_steering_vector(self, method='weighted', threshold=0.1):\n",
    "        \"\"\"\n",
    "        Extract a steering vector that combines information across multiple features,\n",
    "        weighting each feature by its overall prediction performance.\n",
    "        \"\"\"\n",
    "        # Find all available features\n",
    "        available_features = [f for f in self.models.keys()]\n",
    "        if not available_features:\n",
    "            print(\"No models trained for any features\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Combining steering vectors from features: {available_features}\")\n",
    "        \n",
    "        # Get individual steering vectors for each feature\n",
    "        feature_vectors = {}\n",
    "        feature_scores = {}\n",
    "        \n",
    "        for feature in available_features:\n",
    "            # Extract steering vector using existing method\n",
    "            vector = self.extract_steering_vector(\n",
    "                feature_name=feature,\n",
    "                method=method,\n",
    "                threshold=threshold\n",
    "            )\n",
    "            \n",
    "            if vector is not None:\n",
    "                feature_vectors[feature] = vector\n",
    "                \n",
    "                # Get average correlation score for this feature\n",
    "                feature_data = self.models[feature]\n",
    "                if isinstance(feature_data, dict) and 'results' in feature_data:\n",
    "                    mean_corr = np.mean([np.mean(r['correlations']) for r in feature_data['results']])\n",
    "                else:\n",
    "                    mean_corr = np.mean([np.mean(r['correlations']) for r in feature_data['results']])\n",
    "                \n",
    "                feature_scores[feature] = mean_corr\n",
    "        \n",
    "        if not feature_vectors:\n",
    "            print(\"No valid steering vectors extracted\")\n",
    "            return None\n",
    "        \n",
    "        # Weight features by their scores\n",
    "        total_score = sum(feature_scores.values())\n",
    "        weights = {f: score/total_score for f, score in feature_scores.items()}\n",
    "        \n",
    "        # Combine vectors (they should all have the same dimensionality)\n",
    "        dim = len(next(iter(feature_vectors.values())))\n",
    "        combined_vector = np.zeros(dim)\n",
    "        \n",
    "        for feature, vector in feature_vectors.items():\n",
    "            combined_vector += weights[feature] * vector\n",
    "        \n",
    "        # Normalize\n",
    "        combined_vector = combined_vector / np.linalg.norm(combined_vector)\n",
    "        \n",
    "        return combined_vector\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00746a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZKB_SR.mat\n",
      "Extracted 7129 words from subject resultsZKB_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZDM_SR.mat\n",
      "Extracted 7129 words from subject resultsZDM_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZJN_SR.mat\n",
      "Extracted 7129 words from subject resultsZJN_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZAB_SR.mat\n",
      "Extracted 7129 words from subject resultsZAB_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZKH_SR.mat\n",
      "Extracted 7129 words from subject resultsZKH_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZMG_SR.mat\n",
      "Extracted 7129 words from subject resultsZMG_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZGW_SR.mat\n",
      "Extracted 7129 words from subject resultsZGW_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZKW_SR.mat\n",
      "Extracted 7129 words from subject resultsZKW_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZJM_SR.mat\n",
      "Extracted 7129 words from subject resultsZJM_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZDN_SR.mat\n",
      "Sentence 150 words is not iterable: <class 'float'>\n",
      "Sentence 151 words is not iterable: <class 'float'>\n",
      "Sentence 152 words is not iterable: <class 'float'>\n",
      "Sentence 153 words is not iterable: <class 'float'>\n",
      "Sentence 154 words is not iterable: <class 'float'>\n",
      "Sentence 155 words is not iterable: <class 'float'>\n",
      "Sentence 156 words is not iterable: <class 'float'>\n",
      "Sentence 157 words is not iterable: <class 'float'>\n",
      "Sentence 158 words is not iterable: <class 'float'>\n",
      "Sentence 159 words is not iterable: <class 'float'>\n",
      "Sentence 160 words is not iterable: <class 'float'>\n",
      "Sentence 161 words is not iterable: <class 'float'>\n",
      "Sentence 162 words is not iterable: <class 'float'>\n",
      "Sentence 163 words is not iterable: <class 'float'>\n",
      "Sentence 164 words is not iterable: <class 'float'>\n",
      "Sentence 165 words is not iterable: <class 'float'>\n",
      "Sentence 166 words is not iterable: <class 'float'>\n",
      "Sentence 167 words is not iterable: <class 'float'>\n",
      "Sentence 168 words is not iterable: <class 'float'>\n",
      "Sentence 169 words is not iterable: <class 'float'>\n",
      "Sentence 170 words is not iterable: <class 'float'>\n",
      "Sentence 171 words is not iterable: <class 'float'>\n",
      "Sentence 172 words is not iterable: <class 'float'>\n",
      "Sentence 173 words is not iterable: <class 'float'>\n",
      "Sentence 174 words is not iterable: <class 'float'>\n",
      "Sentence 175 words is not iterable: <class 'float'>\n",
      "Sentence 176 words is not iterable: <class 'float'>\n",
      "Sentence 177 words is not iterable: <class 'float'>\n",
      "Sentence 178 words is not iterable: <class 'float'>\n",
      "Sentence 179 words is not iterable: <class 'float'>\n",
      "Sentence 180 words is not iterable: <class 'float'>\n",
      "Sentence 181 words is not iterable: <class 'float'>\n",
      "Sentence 182 words is not iterable: <class 'float'>\n",
      "Sentence 183 words is not iterable: <class 'float'>\n",
      "Sentence 184 words is not iterable: <class 'float'>\n",
      "Sentence 185 words is not iterable: <class 'float'>\n",
      "Sentence 186 words is not iterable: <class 'float'>\n",
      "Sentence 187 words is not iterable: <class 'float'>\n",
      "Sentence 188 words is not iterable: <class 'float'>\n",
      "Sentence 189 words is not iterable: <class 'float'>\n",
      "Sentence 190 words is not iterable: <class 'float'>\n",
      "Sentence 191 words is not iterable: <class 'float'>\n",
      "Sentence 192 words is not iterable: <class 'float'>\n",
      "Sentence 193 words is not iterable: <class 'float'>\n",
      "Sentence 194 words is not iterable: <class 'float'>\n",
      "Sentence 195 words is not iterable: <class 'float'>\n",
      "Sentence 196 words is not iterable: <class 'float'>\n",
      "Sentence 197 words is not iterable: <class 'float'>\n",
      "Sentence 198 words is not iterable: <class 'float'>\n",
      "Sentence 199 words is not iterable: <class 'float'>\n",
      "Sentence 200 words is not iterable: <class 'float'>\n",
      "Sentence 201 words is not iterable: <class 'float'>\n",
      "Sentence 202 words is not iterable: <class 'float'>\n",
      "Sentence 203 words is not iterable: <class 'float'>\n",
      "Sentence 204 words is not iterable: <class 'float'>\n",
      "Sentence 205 words is not iterable: <class 'float'>\n",
      "Sentence 206 words is not iterable: <class 'float'>\n",
      "Sentence 207 words is not iterable: <class 'float'>\n",
      "Sentence 208 words is not iterable: <class 'float'>\n",
      "Sentence 209 words is not iterable: <class 'float'>\n",
      "Sentence 210 words is not iterable: <class 'float'>\n",
      "Sentence 211 words is not iterable: <class 'float'>\n",
      "Sentence 212 words is not iterable: <class 'float'>\n",
      "Sentence 213 words is not iterable: <class 'float'>\n",
      "Sentence 214 words is not iterable: <class 'float'>\n",
      "Sentence 215 words is not iterable: <class 'float'>\n",
      "Sentence 216 words is not iterable: <class 'float'>\n",
      "Sentence 217 words is not iterable: <class 'float'>\n",
      "Sentence 218 words is not iterable: <class 'float'>\n",
      "Sentence 219 words is not iterable: <class 'float'>\n",
      "Sentence 220 words is not iterable: <class 'float'>\n",
      "Sentence 221 words is not iterable: <class 'float'>\n",
      "Sentence 222 words is not iterable: <class 'float'>\n",
      "Sentence 223 words is not iterable: <class 'float'>\n",
      "Sentence 224 words is not iterable: <class 'float'>\n",
      "Sentence 225 words is not iterable: <class 'float'>\n",
      "Sentence 226 words is not iterable: <class 'float'>\n",
      "Sentence 227 words is not iterable: <class 'float'>\n",
      "Sentence 228 words is not iterable: <class 'float'>\n",
      "Sentence 229 words is not iterable: <class 'float'>\n",
      "Sentence 230 words is not iterable: <class 'float'>\n",
      "Sentence 231 words is not iterable: <class 'float'>\n",
      "Sentence 232 words is not iterable: <class 'float'>\n",
      "Sentence 233 words is not iterable: <class 'float'>\n",
      "Sentence 234 words is not iterable: <class 'float'>\n",
      "Sentence 235 words is not iterable: <class 'float'>\n",
      "Sentence 236 words is not iterable: <class 'float'>\n",
      "Sentence 237 words is not iterable: <class 'float'>\n",
      "Sentence 238 words is not iterable: <class 'float'>\n",
      "Sentence 239 words is not iterable: <class 'float'>\n",
      "Sentence 240 words is not iterable: <class 'float'>\n",
      "Sentence 241 words is not iterable: <class 'float'>\n",
      "Sentence 242 words is not iterable: <class 'float'>\n",
      "Sentence 243 words is not iterable: <class 'float'>\n",
      "Sentence 244 words is not iterable: <class 'float'>\n",
      "Sentence 245 words is not iterable: <class 'float'>\n",
      "Sentence 246 words is not iterable: <class 'float'>\n",
      "Sentence 247 words is not iterable: <class 'float'>\n",
      "Sentence 248 words is not iterable: <class 'float'>\n",
      "Sentence 249 words is not iterable: <class 'float'>\n",
      "Sentence 399 words is not iterable: <class 'float'>\n",
      "Extracted 5293 words from subject resultsZDN_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZJS_SR.mat\n",
      "Extracted 7129 words from subject resultsZJS_SR\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZPH_SR.mat\n",
      "Extracted 7129 words from subject resultsZPH_SR\n",
      "Saved subject data to saved_data/subject_word_data.pkl\n",
      "Loading model gpt2-medium...\n",
      "Loaded pretrained model gpt2-medium into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings:   0%|          | 0/1 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.97s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.64s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint after 50/400 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.92s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.56s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint after 100/400 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.67s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint after 150/400 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.60s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint after 200/400 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.58s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.14s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.53s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint after 250/400 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:05<00:00,  5.58s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.60s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint after 300/400 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.21s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.33s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.87s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint after 350/400 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.65s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Extracting embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint after 400/400 sentences\n",
      "Saved embeddings to saved_data/embeddings.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Initialize the data loader\n",
    "zuco_loader = ZucoDataLoader(data_dir='../zuco_data/zuco1.0/task1-SR/Matlab files')\n",
    "\n",
    "# 2. Extract and save word-level data for all subjects\n",
    "all_subjects_data = {}\n",
    "subject_data_path = Path('saved_data/subject_word_data.pkl')\n",
    "subject_data_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if subject_data_path.exists():\n",
    "    print(f\"Loading subject data from {subject_data_path}\")\n",
    "    with open(subject_data_path, 'rb') as f:\n",
    "        all_subjects_data = pickle.load(f)\n",
    "else:\n",
    "    for subject_id in zuco_loader.get_subject_ids():\n",
    "        word_data = zuco_loader.extract_word_level_data(subject_id)\n",
    "        all_subjects_data[subject_id] = word_data\n",
    "        print(f\"Extracted {len(word_data)} words from subject {subject_id}\")\n",
    "        \n",
    "    # Save the results\n",
    "    with open(subject_data_path, 'wb') as f:\n",
    "        pickle.dump(all_subjects_data, f)\n",
    "    print(f\"Saved subject data to {subject_data_path}\")\n",
    "\n",
    "# 3. Generate embeddings with checkpoints\n",
    "embeddings_path = Path('saved_data/embeddings.pkl')\n",
    "\n",
    "if embeddings_path.exists():\n",
    "    print(f\"Loading embeddings from {embeddings_path}\")\n",
    "    with open(embeddings_path, 'rb') as f:\n",
    "        sentence_embeddings = pickle.load(f)\n",
    "else:\n",
    "    # Gather unique sentences across all subjects\n",
    "    unique_sentences = {}\n",
    "    for subject_id, word_data in all_subjects_data.items():\n",
    "        for word in word_data:\n",
    "            sent_id = word['sentence_id']\n",
    "            if sent_id not in unique_sentences:\n",
    "                unique_sentences[sent_id] = word['sentence']\n",
    "    \n",
    "    # Initialize embeddings generator\n",
    "    embedding_gen = EmbeddingGenerator(model_name='gpt2-medium')\n",
    "    sentence_embeddings = {}\n",
    "    \n",
    "    # Generate embeddings with checkpoints\n",
    "    checkpoint_path = Path('saved_data/embeddings_checkpoint.pkl')\n",
    "    \n",
    "    try:\n",
    "        # If checkpoint exists, load it\n",
    "        if checkpoint_path.exists():\n",
    "            with open(checkpoint_path, 'rb') as f:\n",
    "                sentence_embeddings = pickle.load(f)\n",
    "            print(f\"Loaded checkpoint with {len(sentence_embeddings)} sentences\")\n",
    "        \n",
    "        # Process remaining sentences\n",
    "        remaining_sentences = {k: v for k, v in unique_sentences.items() \n",
    "                               if k not in sentence_embeddings}\n",
    "        \n",
    "        for i, (sent_id, sentence) in enumerate(remaining_sentences.items()):\n",
    "            # Create dummy word data structure for the embeddings function\n",
    "            words = sentence.split()\n",
    "            dummy_words = [{'word': word, 'word_idx': i, 'sentence_id': sent_id, \n",
    "                           'sentence': sentence, 'eeg_features': {}} \n",
    "                           for i, word in enumerate(words)]\n",
    "            \n",
    "            embeddings = embedding_gen.extract_embeddings_sliding_window(dummy_words)\n",
    "            sentence_embeddings[sent_id] = {e['word_idx']: e['embedding'] for e in embeddings}\n",
    "            \n",
    "            # Save checkpoint every 50 sentences\n",
    "            if (i + 1) % 50 == 0:\n",
    "                with open(checkpoint_path, 'wb') as f:\n",
    "                    pickle.dump(sentence_embeddings, f)\n",
    "                print(f\"Saved checkpoint after {i+1}/{len(remaining_sentences)} sentences\")\n",
    "                \n",
    "        # Save final embeddings\n",
    "        with open(embeddings_path, 'wb') as f:\n",
    "            pickle.dump(sentence_embeddings, f)\n",
    "        print(f\"Saved embeddings to {embeddings_path}\")\n",
    "        \n",
    "        # Remove checkpoint file\n",
    "        if checkpoint_path.exists():\n",
    "            os.remove(checkpoint_path)\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Save checkpoint on error\n",
    "        print(f\"Error during embedding generation: {e}\")\n",
    "        with open(checkpoint_path, 'wb') as f:\n",
    "            pickle.dump(sentence_embeddings, f)\n",
    "        print(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b35d6",
   "metadata": {},
   "source": [
    "# linear mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1cbdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 4829 samples with valid data\n",
      "Training model for FFD_a1 with 4828 samples\n",
      "Training model for FFD_a2 with 4828 samples\n",
      "Training model for FFD_b1 with 4828 samples\n",
      "Training model for FFD_b2 with 4828 samples\n",
      "Training model for FFD_g1 with 4828 samples\n",
      "Training model for FFD_g2 with 4828 samples\n",
      "Training model for FFD_t1 with 4828 samples\n",
      "Training model for FFD_t2 with 4828 samples\n",
      "Training model for GD_a1 with 4829 samples\n",
      "Training model for GD_a2 with 4829 samples\n",
      "Training model for GD_b1 with 4829 samples\n",
      "Training model for GD_b2 with 4829 samples\n",
      "Training model for GD_g1 with 4829 samples\n",
      "Training model for GD_g2 with 4829 samples\n",
      "Training model for GD_t1 with 4829 samples\n",
      "Training model for GD_t2 with 4829 samples\n",
      "Training model for GPT_a1 with 4829 samples\n",
      "Training model for GPT_a2 with 4829 samples\n",
      "Training model for GPT_b1 with 4829 samples\n",
      "Training model for GPT_b2 with 4829 samples\n",
      "Training model for GPT_g1 with 4829 samples\n",
      "Training model for GPT_g2 with 4829 samples\n",
      "Training model for GPT_t1 with 4829 samples\n",
      "Training model for GPT_t2 with 4829 samples\n",
      "Training model for TRT_a1 with 4829 samples\n",
      "Training model for TRT_a2 with 4829 samples\n",
      "Training model for TRT_b1 with 4829 samples\n",
      "Training model for TRT_b2 with 4829 samples\n",
      "Training model for TRT_g1 with 4829 samples\n",
      "Training model for TRT_g2 with 4829 samples\n",
      "Training model for TRT_t1 with 4829 samples\n",
      "Training model for TRT_t2 with 4829 samples\n",
      "Saved results for subject resultsZKB_SR\n",
      "Feature FFD_a1: Mean correlation = 0.0864\n",
      "Feature FFD_a2: Mean correlation = 0.0909\n",
      "Feature FFD_b1: Mean correlation = 0.0648\n",
      "Feature FFD_b2: Mean correlation = 0.0885\n",
      "Feature FFD_g1: Mean correlation = 0.1138\n",
      "Feature FFD_g2: Mean correlation = 0.1178\n",
      "Feature FFD_t1: Mean correlation = 0.0744\n",
      "Feature FFD_t2: Mean correlation = 0.0741\n",
      "Feature GD_a1: Mean correlation = 0.0876\n",
      "Feature GD_a2: Mean correlation = 0.0858\n",
      "Feature GD_b1: Mean correlation = 0.0666\n",
      "Feature GD_b2: Mean correlation = 0.0983\n",
      "Feature GD_g1: Mean correlation = 0.1149\n",
      "Feature GD_g2: Mean correlation = 0.1201\n",
      "Feature GD_t1: Mean correlation = 0.0790\n",
      "Feature GD_t2: Mean correlation = 0.0782\n",
      "Feature GPT_a1: Mean correlation = 0.1114\n",
      "Feature GPT_a2: Mean correlation = 0.1126\n",
      "Feature GPT_b1: Mean correlation = 0.0894\n",
      "Feature GPT_b2: Mean correlation = 0.1245\n",
      "Feature GPT_g1: Mean correlation = 0.1437\n",
      "Feature GPT_g2: Mean correlation = 0.1451\n",
      "Feature GPT_t1: Mean correlation = 0.0997\n",
      "Feature GPT_t2: Mean correlation = 0.1025\n",
      "Feature TRT_a1: Mean correlation = 0.0975\n",
      "Feature TRT_a2: Mean correlation = 0.0967\n",
      "Feature TRT_b1: Mean correlation = 0.0686\n",
      "Feature TRT_b2: Mean correlation = 0.1089\n",
      "Feature TRT_g1: Mean correlation = 0.1297\n",
      "Feature TRT_g2: Mean correlation = 0.1389\n",
      "Feature TRT_t1: Mean correlation = 0.0861\n",
      "Feature TRT_t2: Mean correlation = 0.0881\n",
      "Subject resultsZKB_SR: Overall mean correlation = 0.0995\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 4354 samples with valid data\n",
      "Training model for FFD_a1 with 4348 samples\n",
      "Training model for FFD_a2 with 4348 samples\n",
      "Training model for FFD_b1 with 4348 samples\n",
      "Training model for FFD_b2 with 4348 samples\n",
      "Training model for FFD_g1 with 4348 samples\n",
      "Training model for FFD_g2 with 4348 samples\n",
      "Training model for FFD_t1 with 4348 samples\n",
      "Training model for FFD_t2 with 4348 samples\n",
      "Training model for GD_a1 with 4348 samples\n",
      "Training model for GD_a2 with 4348 samples\n",
      "Training model for GD_b1 with 4348 samples\n",
      "Training model for GD_b2 with 4348 samples\n",
      "Training model for GD_g1 with 4348 samples\n",
      "Training model for GD_g2 with 4348 samples\n",
      "Training model for GD_t1 with 4348 samples\n",
      "Training model for GD_t2 with 4348 samples\n",
      "Training model for GPT_a1 with 4351 samples\n",
      "Training model for GPT_a2 with 4351 samples\n",
      "Training model for GPT_b1 with 4351 samples\n",
      "Training model for GPT_b2 with 4351 samples\n",
      "Training model for GPT_g1 with 4351 samples\n",
      "Training model for GPT_g2 with 4351 samples\n",
      "Training model for GPT_t1 with 4351 samples\n",
      "Training model for GPT_t2 with 4351 samples\n",
      "Training model for TRT_a1 with 4354 samples\n",
      "Training model for TRT_a2 with 4354 samples\n",
      "Training model for TRT_b1 with 4354 samples\n",
      "Training model for TRT_b2 with 4354 samples\n",
      "Training model for TRT_g1 with 4354 samples\n",
      "Training model for TRT_g2 with 4354 samples\n",
      "Training model for TRT_t1 with 4354 samples\n",
      "Training model for TRT_t2 with 4354 samples\n",
      "Saved results for subject resultsZDM_SR\n",
      "Feature FFD_a1: Mean correlation = 0.1038\n",
      "Feature FFD_a2: Mean correlation = 0.0875\n",
      "Feature FFD_b1: Mean correlation = 0.0770\n",
      "Feature FFD_b2: Mean correlation = 0.0586\n",
      "Feature FFD_g1: Mean correlation = 0.0825\n",
      "Feature FFD_g2: Mean correlation = 0.0915\n",
      "Feature FFD_t1: Mean correlation = 0.0733\n",
      "Feature FFD_t2: Mean correlation = 0.0863\n",
      "Feature GD_a1: Mean correlation = 0.1034\n",
      "Feature GD_a2: Mean correlation = 0.0886\n",
      "Feature GD_b1: Mean correlation = 0.0761\n",
      "Feature GD_b2: Mean correlation = 0.0586\n",
      "Feature GD_g1: Mean correlation = 0.0860\n",
      "Feature GD_g2: Mean correlation = 0.0949\n",
      "Feature GD_t1: Mean correlation = 0.0749\n",
      "Feature GD_t2: Mean correlation = 0.0888\n",
      "Feature GPT_a1: Mean correlation = 0.1093\n",
      "Feature GPT_a2: Mean correlation = 0.1007\n",
      "Feature GPT_b1: Mean correlation = 0.0764\n",
      "Feature GPT_b2: Mean correlation = 0.0734\n",
      "Feature GPT_g1: Mean correlation = 0.1168\n",
      "Feature GPT_g2: Mean correlation = 0.1130\n",
      "Feature GPT_t1: Mean correlation = 0.0813\n",
      "Feature GPT_t2: Mean correlation = 0.0949\n",
      "Feature TRT_a1: Mean correlation = 0.1088\n",
      "Feature TRT_a2: Mean correlation = 0.0947\n",
      "Feature TRT_b1: Mean correlation = 0.0760\n",
      "Feature TRT_b2: Mean correlation = 0.0695\n",
      "Feature TRT_g1: Mean correlation = 0.0951\n",
      "Feature TRT_g2: Mean correlation = 0.1043\n",
      "Feature TRT_t1: Mean correlation = 0.0874\n",
      "Feature TRT_t2: Mean correlation = 0.0955\n",
      "Subject resultsZDM_SR: Overall mean correlation = 0.0884\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 5653 samples with valid data\n",
      "Training model for FFD_a1 with 5646 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94307e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_a2 with 5646 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94307e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_b1 with 5646 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94307e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_b2 with 5646 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94307e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_g1 with 5646 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94307e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_g2 with 5646 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94307e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_t1 with 5646 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94307e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_t2 with 5646 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94307e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94974e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_a1 with 5648 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94649e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93508e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_a2 with 5648 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94974e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94649e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93508e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_b1 with 5648 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94974e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94649e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93508e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_b2 with 5648 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94974e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94649e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93508e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_g1 with 5648 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94974e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94649e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93508e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_g2 with 5648 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94974e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94649e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93508e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_t1 with 5648 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94974e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94649e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93508e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_t2 with 5648 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94974e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94649e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93508e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_a1 with 5652 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.959e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_a2 with 5652 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.959e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_b1 with 5652 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.959e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_b2 with 5652 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.959e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_g1 with 5652 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.959e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_g2 with 5652 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.959e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_t1 with 5652 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.959e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_t2 with 5652 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.959e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_a1 with 5650 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.83992e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_a2 with 5650 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.83992e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_b1 with 5650 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.83992e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_b2 with 5650 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.83992e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_g1 with 5650 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.83992e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_g2 with 5650 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.83992e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_t1 with 5650 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.83992e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_t2 with 5650 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.83992e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for subject resultsZJN_SR\n",
      "Feature FFD_a1: Mean correlation = 0.1108\n",
      "Feature FFD_a2: Mean correlation = 0.1188\n",
      "Feature FFD_b1: Mean correlation = 0.1173\n",
      "Feature FFD_b2: Mean correlation = 0.1513\n",
      "Feature FFD_g1: Mean correlation = 0.1874\n",
      "Feature FFD_g2: Mean correlation = 0.1914\n",
      "Feature FFD_t1: Mean correlation = 0.0926\n",
      "Feature FFD_t2: Mean correlation = 0.1000\n",
      "Feature GD_a1: Mean correlation = 0.1154\n",
      "Feature GD_a2: Mean correlation = 0.1246\n",
      "Feature GD_b1: Mean correlation = 0.1240\n",
      "Feature GD_b2: Mean correlation = 0.1577\n",
      "Feature GD_g1: Mean correlation = 0.1961\n",
      "Feature GD_g2: Mean correlation = 0.1976\n",
      "Feature GD_t1: Mean correlation = 0.0977\n",
      "Feature GD_t2: Mean correlation = 0.0986\n",
      "Feature GPT_a1: Mean correlation = 0.1215\n",
      "Feature GPT_a2: Mean correlation = 0.1362\n",
      "Feature GPT_b1: Mean correlation = 0.1452\n",
      "Feature GPT_b2: Mean correlation = 0.1672\n",
      "Feature GPT_g1: Mean correlation = 0.2083\n",
      "Feature GPT_g2: Mean correlation = 0.2200\n",
      "Feature GPT_t1: Mean correlation = 0.1170\n",
      "Feature GPT_t2: Mean correlation = 0.1142\n",
      "Feature TRT_a1: Mean correlation = 0.1297\n",
      "Feature TRT_a2: Mean correlation = 0.1343\n",
      "Feature TRT_b1: Mean correlation = 0.1380\n",
      "Feature TRT_b2: Mean correlation = 0.1605\n",
      "Feature TRT_g1: Mean correlation = 0.2087\n",
      "Feature TRT_g2: Mean correlation = 0.2121\n",
      "Feature TRT_t1: Mean correlation = 0.1117\n",
      "Feature TRT_t2: Mean correlation = 0.1165\n",
      "Subject resultsZJN_SR: Overall mean correlation = 0.1445\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 5095 samples with valid data\n",
      "Training model for FFD_a1 with 5091 samples\n",
      "Training model for FFD_a2 with 5091 samples\n",
      "Training model for FFD_b1 with 5091 samples\n",
      "Training model for FFD_b2 with 5091 samples\n",
      "Training model for FFD_g1 with 5091 samples\n",
      "Training model for FFD_g2 with 5091 samples\n",
      "Training model for FFD_t1 with 5091 samples\n",
      "Training model for FFD_t2 with 5091 samples\n",
      "Training model for GD_a1 with 5091 samples\n",
      "Training model for GD_a2 with 5091 samples\n",
      "Training model for GD_b1 with 5091 samples\n",
      "Training model for GD_b2 with 5091 samples\n",
      "Training model for GD_g1 with 5091 samples\n",
      "Training model for GD_g2 with 5091 samples\n",
      "Training model for GD_t1 with 5091 samples\n",
      "Training model for GD_t2 with 5091 samples\n",
      "Training model for GPT_a1 with 5092 samples\n",
      "Training model for GPT_a2 with 5092 samples\n",
      "Training model for GPT_b1 with 5092 samples\n",
      "Training model for GPT_b2 with 5092 samples\n",
      "Training model for GPT_g1 with 5092 samples\n",
      "Training model for GPT_g2 with 5092 samples\n",
      "Training model for GPT_t1 with 5092 samples\n",
      "Training model for GPT_t2 with 5092 samples\n",
      "Training model for TRT_a1 with 5095 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.95453e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_a2 with 5095 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.95453e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_b1 with 5095 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.95453e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_b2 with 5095 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.95453e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_g1 with 5095 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.95453e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_g2 with 5095 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.95453e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_t1 with 5095 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.95453e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_t2 with 5095 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.95453e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for subject resultsZAB_SR\n",
      "Feature FFD_a1: Mean correlation = 0.1122\n",
      "Feature FFD_a2: Mean correlation = 0.1166\n",
      "Feature FFD_b1: Mean correlation = 0.1232\n",
      "Feature FFD_b2: Mean correlation = 0.1701\n",
      "Feature FFD_g1: Mean correlation = 0.1953\n",
      "Feature FFD_g2: Mean correlation = 0.1970\n",
      "Feature FFD_t1: Mean correlation = 0.0882\n",
      "Feature FFD_t2: Mean correlation = 0.1064\n",
      "Feature GD_a1: Mean correlation = 0.1167\n",
      "Feature GD_a2: Mean correlation = 0.1232\n",
      "Feature GD_b1: Mean correlation = 0.1289\n",
      "Feature GD_b2: Mean correlation = 0.1801\n",
      "Feature GD_g1: Mean correlation = 0.1994\n",
      "Feature GD_g2: Mean correlation = 0.2033\n",
      "Feature GD_t1: Mean correlation = 0.0944\n",
      "Feature GD_t2: Mean correlation = 0.1096\n",
      "Feature GPT_a1: Mean correlation = 0.1228\n",
      "Feature GPT_a2: Mean correlation = 0.1269\n",
      "Feature GPT_b1: Mean correlation = 0.1410\n",
      "Feature GPT_b2: Mean correlation = 0.1936\n",
      "Feature GPT_g1: Mean correlation = 0.2175\n",
      "Feature GPT_g2: Mean correlation = 0.2144\n",
      "Feature GPT_t1: Mean correlation = 0.1088\n",
      "Feature GPT_t2: Mean correlation = 0.1230\n",
      "Feature TRT_a1: Mean correlation = 0.1226\n",
      "Feature TRT_a2: Mean correlation = 0.1263\n",
      "Feature TRT_b1: Mean correlation = 0.1398\n",
      "Feature TRT_b2: Mean correlation = 0.1926\n",
      "Feature TRT_g1: Mean correlation = 0.2120\n",
      "Feature TRT_g2: Mean correlation = 0.2141\n",
      "Feature TRT_t1: Mean correlation = 0.1045\n",
      "Feature TRT_t2: Mean correlation = 0.1184\n",
      "Subject resultsZAB_SR: Overall mean correlation = 0.1482\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 5012 samples with valid data\n",
      "Training model for FFD_a1 with 5009 samples\n",
      "Training model for FFD_a2 with 5009 samples\n",
      "Training model for FFD_b1 with 5009 samples\n",
      "Training model for FFD_b2 with 5009 samples\n",
      "Training model for FFD_g1 with 5009 samples\n",
      "Training model for FFD_g2 with 5009 samples\n",
      "Training model for FFD_t1 with 5009 samples\n",
      "Training model for FFD_t2 with 5009 samples\n",
      "Training model for GD_a1 with 5012 samples\n",
      "Training model for GD_a2 with 5012 samples\n",
      "Training model for GD_b1 with 5012 samples\n",
      "Training model for GD_b2 with 5012 samples\n",
      "Training model for GD_g1 with 5012 samples\n",
      "Training model for GD_g2 with 5012 samples\n",
      "Training model for GD_t1 with 5012 samples\n",
      "Training model for GD_t2 with 5012 samples\n",
      "Training model for GPT_a1 with 5012 samples\n",
      "Training model for GPT_a2 with 5012 samples\n",
      "Training model for GPT_b1 with 5012 samples\n",
      "Training model for GPT_b2 with 5012 samples\n",
      "Training model for GPT_g1 with 5012 samples\n",
      "Training model for GPT_g2 with 5012 samples\n",
      "Training model for GPT_t1 with 5012 samples\n",
      "Training model for GPT_t2 with 5012 samples\n",
      "Training model for TRT_a1 with 5012 samples\n",
      "Training model for TRT_a2 with 5012 samples\n",
      "Training model for TRT_b1 with 5012 samples\n",
      "Training model for TRT_b2 with 5012 samples\n",
      "Training model for TRT_g1 with 5012 samples\n",
      "Training model for TRT_g2 with 5012 samples\n",
      "Training model for TRT_t1 with 5012 samples\n",
      "Training model for TRT_t2 with 5012 samples\n",
      "Saved results for subject resultsZKH_SR\n",
      "Feature FFD_a1: Mean correlation = 0.0864\n",
      "Feature FFD_a2: Mean correlation = 0.0886\n",
      "Feature FFD_b1: Mean correlation = 0.0751\n",
      "Feature FFD_b2: Mean correlation = 0.0947\n",
      "Feature FFD_g1: Mean correlation = 0.0930\n",
      "Feature FFD_g2: Mean correlation = 0.1132\n",
      "Feature FFD_t1: Mean correlation = 0.0672\n",
      "Feature FFD_t2: Mean correlation = 0.0851\n",
      "Feature GD_a1: Mean correlation = 0.0999\n",
      "Feature GD_a2: Mean correlation = 0.0922\n",
      "Feature GD_b1: Mean correlation = 0.0736\n",
      "Feature GD_b2: Mean correlation = 0.1062\n",
      "Feature GD_g1: Mean correlation = 0.1018\n",
      "Feature GD_g2: Mean correlation = 0.1222\n",
      "Feature GD_t1: Mean correlation = 0.0751\n",
      "Feature GD_t2: Mean correlation = 0.0923\n",
      "Feature GPT_a1: Mean correlation = 0.1131\n",
      "Feature GPT_a2: Mean correlation = 0.1053\n",
      "Feature GPT_b1: Mean correlation = 0.0871\n",
      "Feature GPT_b2: Mean correlation = 0.1191\n",
      "Feature GPT_g1: Mean correlation = 0.1116\n",
      "Feature GPT_g2: Mean correlation = 0.1310\n",
      "Feature GPT_t1: Mean correlation = 0.0850\n",
      "Feature GPT_t2: Mean correlation = 0.1027\n",
      "Feature TRT_a1: Mean correlation = 0.1078\n",
      "Feature TRT_a2: Mean correlation = 0.1015\n",
      "Feature TRT_b1: Mean correlation = 0.0770\n",
      "Feature TRT_b2: Mean correlation = 0.1165\n",
      "Feature TRT_g1: Mean correlation = 0.1087\n",
      "Feature TRT_g2: Mean correlation = 0.1284\n",
      "Feature TRT_t1: Mean correlation = 0.0818\n",
      "Feature TRT_t2: Mean correlation = 0.0983\n",
      "Subject resultsZKH_SR: Overall mean correlation = 0.0982\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 4325 samples with valid data\n",
      "Training model for FFD_a1 with 4318 samples\n",
      "Training model for FFD_a2 with 4318 samples\n",
      "Training model for FFD_b1 with 4318 samples\n",
      "Training model for FFD_b2 with 4318 samples\n",
      "Training model for FFD_g1 with 4318 samples\n",
      "Training model for FFD_g2 with 4318 samples\n",
      "Training model for FFD_t1 with 4318 samples\n",
      "Training model for FFD_t2 with 4318 samples\n",
      "Training model for GD_a1 with 4319 samples\n",
      "Training model for GD_a2 with 4319 samples\n",
      "Training model for GD_b1 with 4319 samples\n",
      "Training model for GD_b2 with 4319 samples\n",
      "Training model for GD_g1 with 4319 samples\n",
      "Training model for GD_g2 with 4319 samples\n",
      "Training model for GD_t1 with 4319 samples\n",
      "Training model for GD_t2 with 4319 samples\n",
      "Training model for GPT_a1 with 4322 samples\n",
      "Training model for GPT_a2 with 4322 samples\n",
      "Training model for GPT_b1 with 4322 samples\n",
      "Training model for GPT_b2 with 4322 samples\n",
      "Training model for GPT_g1 with 4322 samples\n",
      "Training model for GPT_g2 with 4322 samples\n",
      "Training model for GPT_t1 with 4322 samples\n",
      "Training model for GPT_t2 with 4322 samples\n",
      "Training model for TRT_a1 with 4324 samples\n",
      "Training model for TRT_a2 with 4324 samples\n",
      "Training model for TRT_b1 with 4324 samples\n",
      "Training model for TRT_b2 with 4324 samples\n",
      "Training model for TRT_g1 with 4324 samples\n",
      "Training model for TRT_g2 with 4324 samples\n",
      "Training model for TRT_t1 with 4324 samples\n",
      "Training model for TRT_t2 with 4324 samples\n",
      "Saved results for subject resultsZMG_SR\n",
      "Feature FFD_a1: Mean correlation = 0.1010\n",
      "Feature FFD_a2: Mean correlation = 0.0956\n",
      "Feature FFD_b1: Mean correlation = 0.0699\n",
      "Feature FFD_b2: Mean correlation = 0.1109\n",
      "Feature FFD_g1: Mean correlation = 0.1410\n",
      "Feature FFD_g2: Mean correlation = 0.1579\n",
      "Feature FFD_t1: Mean correlation = 0.0699\n",
      "Feature FFD_t2: Mean correlation = 0.0877\n",
      "Feature GD_a1: Mean correlation = 0.1063\n",
      "Feature GD_a2: Mean correlation = 0.0971\n",
      "Feature GD_b1: Mean correlation = 0.0736\n",
      "Feature GD_b2: Mean correlation = 0.1150\n",
      "Feature GD_g1: Mean correlation = 0.1468\n",
      "Feature GD_g2: Mean correlation = 0.1638\n",
      "Feature GD_t1: Mean correlation = 0.0783\n",
      "Feature GD_t2: Mean correlation = 0.0927\n",
      "Feature GPT_a1: Mean correlation = 0.1233\n",
      "Feature GPT_a2: Mean correlation = 0.1130\n",
      "Feature GPT_b1: Mean correlation = 0.0883\n",
      "Feature GPT_b2: Mean correlation = 0.1298\n",
      "Feature GPT_g1: Mean correlation = 0.1693\n",
      "Feature GPT_g2: Mean correlation = 0.1732\n",
      "Feature GPT_t1: Mean correlation = 0.0814\n",
      "Feature GPT_t2: Mean correlation = 0.0958\n",
      "Feature TRT_a1: Mean correlation = 0.1273\n",
      "Feature TRT_a2: Mean correlation = 0.1246\n",
      "Feature TRT_b1: Mean correlation = 0.0860\n",
      "Feature TRT_b2: Mean correlation = 0.1265\n",
      "Feature TRT_g1: Mean correlation = 0.1585\n",
      "Feature TRT_g2: Mean correlation = 0.1706\n",
      "Feature TRT_t1: Mean correlation = 0.0854\n",
      "Feature TRT_t2: Mean correlation = 0.1115\n",
      "Subject resultsZMG_SR: Overall mean correlation = 0.1148\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 4724 samples with valid data\n",
      "Training model for FFD_a1 with 4703 samples\n",
      "Training model for FFD_a2 with 4703 samples\n",
      "Training model for FFD_b1 with 4703 samples\n",
      "Training model for FFD_b2 with 4703 samples\n",
      "Training model for FFD_g1 with 4703 samples\n",
      "Training model for FFD_g2 with 4703 samples\n",
      "Training model for FFD_t1 with 4703 samples\n",
      "Training model for FFD_t2 with 4703 samples\n",
      "Training model for GD_a1 with 4705 samples\n",
      "Training model for GD_a2 with 4705 samples\n",
      "Training model for GD_b1 with 4705 samples\n",
      "Training model for GD_b2 with 4705 samples\n",
      "Training model for GD_g1 with 4705 samples\n",
      "Training model for GD_g2 with 4705 samples\n",
      "Training model for GD_t1 with 4705 samples\n",
      "Training model for GD_t2 with 4705 samples\n",
      "Training model for GPT_a1 with 4711 samples\n",
      "Training model for GPT_a2 with 4711 samples\n",
      "Training model for GPT_b1 with 4711 samples\n",
      "Training model for GPT_b2 with 4711 samples\n",
      "Training model for GPT_g1 with 4711 samples\n",
      "Training model for GPT_g2 with 4711 samples\n",
      "Training model for GPT_t1 with 4711 samples\n",
      "Training model for GPT_t2 with 4711 samples\n",
      "Training model for TRT_a1 with 4720 samples\n",
      "Training model for TRT_a2 with 4720 samples\n",
      "Training model for TRT_b1 with 4720 samples\n",
      "Training model for TRT_b2 with 4720 samples\n",
      "Training model for TRT_g1 with 4720 samples\n",
      "Training model for TRT_g2 with 4720 samples\n",
      "Training model for TRT_t1 with 4720 samples\n",
      "Training model for TRT_t2 with 4720 samples\n",
      "Saved results for subject resultsZGW_SR\n",
      "Feature FFD_a1: Mean correlation = 0.0867\n",
      "Feature FFD_a2: Mean correlation = 0.0901\n",
      "Feature FFD_b1: Mean correlation = 0.1068\n",
      "Feature FFD_b2: Mean correlation = 0.1178\n",
      "Feature FFD_g1: Mean correlation = 0.1450\n",
      "Feature FFD_g2: Mean correlation = 0.1461\n",
      "Feature FFD_t1: Mean correlation = 0.0697\n",
      "Feature FFD_t2: Mean correlation = 0.0636\n",
      "Feature GD_a1: Mean correlation = 0.0874\n",
      "Feature GD_a2: Mean correlation = 0.0952\n",
      "Feature GD_b1: Mean correlation = 0.1058\n",
      "Feature GD_b2: Mean correlation = 0.1205\n",
      "Feature GD_g1: Mean correlation = 0.1389\n",
      "Feature GD_g2: Mean correlation = 0.1415\n",
      "Feature GD_t1: Mean correlation = 0.0744\n",
      "Feature GD_t2: Mean correlation = 0.0663\n",
      "Feature GPT_a1: Mean correlation = 0.1038\n",
      "Feature GPT_a2: Mean correlation = 0.1143\n",
      "Feature GPT_b1: Mean correlation = 0.1231\n",
      "Feature GPT_b2: Mean correlation = 0.1416\n",
      "Feature GPT_g1: Mean correlation = 0.1514\n",
      "Feature GPT_g2: Mean correlation = 0.1568\n",
      "Feature GPT_t1: Mean correlation = 0.0883\n",
      "Feature GPT_t2: Mean correlation = 0.0846\n",
      "Feature TRT_a1: Mean correlation = 0.0999\n",
      "Feature TRT_a2: Mean correlation = 0.1077\n",
      "Feature TRT_b1: Mean correlation = 0.1246\n",
      "Feature TRT_b2: Mean correlation = 0.1463\n",
      "Feature TRT_g1: Mean correlation = 0.1591\n",
      "Feature TRT_g2: Mean correlation = 0.1613\n",
      "Feature TRT_t1: Mean correlation = 0.0929\n",
      "Feature TRT_t2: Mean correlation = 0.0876\n",
      "Subject resultsZGW_SR: Overall mean correlation = 0.1125\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 5241 samples with valid data\n",
      "Training model for FFD_a1 with 5240 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.87281e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88937e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_a2 with 5240 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.87281e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88937e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_b1 with 5240 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.87281e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88937e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_b2 with 5240 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.87281e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88937e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_g1 with 5240 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.87281e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88937e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_g2 with 5240 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.87281e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88937e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_t1 with 5240 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.87281e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88937e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_t2 with 5240 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.87281e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88937e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_a1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_a2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_b1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_b2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_g1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_g2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_t1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_t2 with 5241 samples\n",
      "Training model for GPT_a1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_a2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_b1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_b2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_g1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_g2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_t1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_t2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_a1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_a2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_b1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_b2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_g1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_g2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_t1 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_t2 with 5241 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.86727e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.93815e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for subject resultsZKW_SR\n",
      "Feature FFD_a1: Mean correlation = 0.0580\n",
      "Feature FFD_a2: Mean correlation = 0.0759\n",
      "Feature FFD_b1: Mean correlation = 0.0849\n",
      "Feature FFD_b2: Mean correlation = 0.0917\n",
      "Feature FFD_g1: Mean correlation = 0.0998\n",
      "Feature FFD_g2: Mean correlation = 0.1104\n",
      "Feature FFD_t1: Mean correlation = 0.0481\n",
      "Feature FFD_t2: Mean correlation = 0.0628\n",
      "Feature GD_a1: Mean correlation = 0.0624\n",
      "Feature GD_a2: Mean correlation = 0.0812\n",
      "Feature GD_b1: Mean correlation = 0.0883\n",
      "Feature GD_b2: Mean correlation = 0.0980\n",
      "Feature GD_g1: Mean correlation = 0.1097\n",
      "Feature GD_g2: Mean correlation = 0.1234\n",
      "Feature GD_t1: Mean correlation = 0.0543\n",
      "Feature GD_t2: Mean correlation = 0.0655\n",
      "Feature GPT_a1: Mean correlation = 0.0710\n",
      "Feature GPT_a2: Mean correlation = 0.0898\n",
      "Feature GPT_b1: Mean correlation = 0.1104\n",
      "Feature GPT_b2: Mean correlation = 0.1095\n",
      "Feature GPT_g1: Mean correlation = 0.1264\n",
      "Feature GPT_g2: Mean correlation = 0.1315\n",
      "Feature GPT_t1: Mean correlation = 0.0694\n",
      "Feature GPT_t2: Mean correlation = 0.0718\n",
      "Feature TRT_a1: Mean correlation = 0.0733\n",
      "Feature TRT_a2: Mean correlation = 0.0881\n",
      "Feature TRT_b1: Mean correlation = 0.1020\n",
      "Feature TRT_b2: Mean correlation = 0.1084\n",
      "Feature TRT_g1: Mean correlation = 0.1232\n",
      "Feature TRT_g2: Mean correlation = 0.1353\n",
      "Feature TRT_t1: Mean correlation = 0.0696\n",
      "Feature TRT_t2: Mean correlation = 0.0707\n",
      "Subject resultsZKW_SR: Overall mean correlation = 0.0895\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 5476 samples with valid data\n",
      "Training model for FFD_a1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_a2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_b1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_b2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_g1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_g2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_t1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for FFD_t2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_a1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_a2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_b1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_b2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_g1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_g2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_t1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GD_t2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_a1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_a2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_b1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_b2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_g1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_g2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_t1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for GPT_t2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_a1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_a2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_b1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_b2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_g1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_g2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_t1 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for TRT_t2 with 5476 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.88029e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.92821e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/Users/oshun/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=5.94559e-08): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for subject resultsZJM_SR\n",
      "Feature FFD_a1: Mean correlation = 0.1000\n",
      "Feature FFD_a2: Mean correlation = 0.1039\n",
      "Feature FFD_b1: Mean correlation = 0.1308\n",
      "Feature FFD_b2: Mean correlation = 0.1742\n",
      "Feature FFD_g1: Mean correlation = 0.2003\n",
      "Feature FFD_g2: Mean correlation = 0.2087\n",
      "Feature FFD_t1: Mean correlation = 0.0929\n",
      "Feature FFD_t2: Mean correlation = 0.0903\n",
      "Feature GD_a1: Mean correlation = 0.1041\n",
      "Feature GD_a2: Mean correlation = 0.1068\n",
      "Feature GD_b1: Mean correlation = 0.1379\n",
      "Feature GD_b2: Mean correlation = 0.1831\n",
      "Feature GD_g1: Mean correlation = 0.2047\n",
      "Feature GD_g2: Mean correlation = 0.2138\n",
      "Feature GD_t1: Mean correlation = 0.1019\n",
      "Feature GD_t2: Mean correlation = 0.0956\n",
      "Feature GPT_a1: Mean correlation = 0.1149\n",
      "Feature GPT_a2: Mean correlation = 0.1247\n",
      "Feature GPT_b1: Mean correlation = 0.1511\n",
      "Feature GPT_b2: Mean correlation = 0.1954\n",
      "Feature GPT_g1: Mean correlation = 0.2187\n",
      "Feature GPT_g2: Mean correlation = 0.2275\n",
      "Feature GPT_t1: Mean correlation = 0.1177\n",
      "Feature GPT_t2: Mean correlation = 0.1065\n",
      "Feature TRT_a1: Mean correlation = 0.1178\n",
      "Feature TRT_a2: Mean correlation = 0.1212\n",
      "Feature TRT_b1: Mean correlation = 0.1501\n",
      "Feature TRT_b2: Mean correlation = 0.1926\n",
      "Feature TRT_g1: Mean correlation = 0.2164\n",
      "Feature TRT_g2: Mean correlation = 0.2219\n",
      "Feature TRT_t1: Mean correlation = 0.1147\n",
      "Feature TRT_t2: Mean correlation = 0.1034\n",
      "Subject resultsZJM_SR: Overall mean correlation = 0.1482\n",
      "Training with 32 features\n",
      "No features with consistent electrode count\n",
      "Saved results for subject resultsZDN_SR\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 4677 samples with valid data\n",
      "Training model for FFD_a1 with 4639 samples\n",
      "Training model for FFD_a2 with 4639 samples\n",
      "Training model for FFD_b1 with 4639 samples\n",
      "Training model for FFD_b2 with 4639 samples\n",
      "Training model for FFD_g1 with 4639 samples\n",
      "Training model for FFD_g2 with 4639 samples\n",
      "Training model for FFD_t1 with 4639 samples\n",
      "Training model for FFD_t2 with 4639 samples\n",
      "Training model for GD_a1 with 4652 samples\n",
      "Training model for GD_a2 with 4652 samples\n",
      "Training model for GD_b1 with 4652 samples\n",
      "Training model for GD_b2 with 4652 samples\n",
      "Training model for GD_g1 with 4652 samples\n",
      "Training model for GD_g2 with 4652 samples\n",
      "Training model for GD_t1 with 4652 samples\n",
      "Training model for GD_t2 with 4652 samples\n",
      "Training model for GPT_a1 with 4664 samples\n",
      "Training model for GPT_a2 with 4664 samples\n",
      "Training model for GPT_b1 with 4664 samples\n",
      "Training model for GPT_b2 with 4664 samples\n",
      "Training model for GPT_g1 with 4664 samples\n",
      "Training model for GPT_g2 with 4664 samples\n",
      "Training model for GPT_t1 with 4664 samples\n",
      "Training model for GPT_t2 with 4664 samples\n",
      "Training model for TRT_a1 with 4672 samples\n",
      "Training model for TRT_a2 with 4672 samples\n",
      "Training model for TRT_b1 with 4672 samples\n",
      "Training model for TRT_b2 with 4672 samples\n",
      "Training model for TRT_g1 with 4672 samples\n",
      "Training model for TRT_g2 with 4672 samples\n",
      "Training model for TRT_t1 with 4672 samples\n",
      "Training model for TRT_t2 with 4672 samples\n",
      "Saved results for subject resultsZJS_SR\n",
      "Feature FFD_a1: Mean correlation = 0.1648\n",
      "Feature FFD_a2: Mean correlation = 0.1710\n",
      "Feature FFD_b1: Mean correlation = 0.1680\n",
      "Feature FFD_b2: Mean correlation = 0.1970\n",
      "Feature FFD_g1: Mean correlation = 0.1995\n",
      "Feature FFD_g2: Mean correlation = 0.2061\n",
      "Feature FFD_t1: Mean correlation = 0.1304\n",
      "Feature FFD_t2: Mean correlation = 0.1360\n",
      "Feature GD_a1: Mean correlation = 0.1715\n",
      "Feature GD_a2: Mean correlation = 0.1741\n",
      "Feature GD_b1: Mean correlation = 0.1730\n",
      "Feature GD_b2: Mean correlation = 0.2035\n",
      "Feature GD_g1: Mean correlation = 0.2081\n",
      "Feature GD_g2: Mean correlation = 0.2158\n",
      "Feature GD_t1: Mean correlation = 0.1323\n",
      "Feature GD_t2: Mean correlation = 0.1447\n",
      "Feature GPT_a1: Mean correlation = 0.1784\n",
      "Feature GPT_a2: Mean correlation = 0.1858\n",
      "Feature GPT_b1: Mean correlation = 0.1899\n",
      "Feature GPT_b2: Mean correlation = 0.2133\n",
      "Feature GPT_g1: Mean correlation = 0.2120\n",
      "Feature GPT_g2: Mean correlation = 0.2186\n",
      "Feature GPT_t1: Mean correlation = 0.1424\n",
      "Feature GPT_t2: Mean correlation = 0.1458\n",
      "Feature TRT_a1: Mean correlation = 0.1827\n",
      "Feature TRT_a2: Mean correlation = 0.1786\n",
      "Feature TRT_b1: Mean correlation = 0.1776\n",
      "Feature TRT_b2: Mean correlation = 0.2029\n",
      "Feature TRT_g1: Mean correlation = 0.2094\n",
      "Feature TRT_g2: Mean correlation = 0.2139\n",
      "Feature TRT_t1: Mean correlation = 0.1355\n",
      "Feature TRT_t2: Mean correlation = 0.1507\n",
      "Subject resultsZJS_SR: Overall mean correlation = 0.1792\n",
      "Training with 32 features\n",
      "Using 32 features with 105 electrodes\n",
      "Found 4713 samples with valid data\n",
      "Training model for FFD_a1 with 4712 samples\n",
      "Training model for FFD_a2 with 4712 samples\n",
      "Training model for FFD_b1 with 4712 samples\n",
      "Training model for FFD_b2 with 4712 samples\n",
      "Training model for FFD_g1 with 4712 samples\n",
      "Training model for FFD_g2 with 4712 samples\n",
      "Training model for FFD_t1 with 4712 samples\n",
      "Training model for FFD_t2 with 4712 samples\n",
      "Training model for GD_a1 with 4712 samples\n",
      "Training model for GD_a2 with 4712 samples\n",
      "Training model for GD_b1 with 4712 samples\n",
      "Training model for GD_b2 with 4712 samples\n",
      "Training model for GD_g1 with 4712 samples\n",
      "Training model for GD_g2 with 4712 samples\n",
      "Training model for GD_t1 with 4712 samples\n",
      "Training model for GD_t2 with 4712 samples\n",
      "Training model for GPT_a1 with 4712 samples\n",
      "Training model for GPT_a2 with 4712 samples\n",
      "Training model for GPT_b1 with 4712 samples\n",
      "Training model for GPT_b2 with 4712 samples\n",
      "Training model for GPT_g1 with 4712 samples\n",
      "Training model for GPT_g2 with 4712 samples\n",
      "Training model for GPT_t1 with 4712 samples\n",
      "Training model for GPT_t2 with 4712 samples\n",
      "Training model for TRT_a1 with 4713 samples\n",
      "Training model for TRT_a2 with 4713 samples\n",
      "Training model for TRT_b1 with 4713 samples\n",
      "Training model for TRT_b2 with 4713 samples\n",
      "Training model for TRT_g1 with 4713 samples\n",
      "Training model for TRT_g2 with 4713 samples\n",
      "Training model for TRT_t1 with 4713 samples\n",
      "Training model for TRT_t2 with 4713 samples\n",
      "Saved results for subject resultsZPH_SR\n",
      "Feature FFD_a1: Mean correlation = 0.0748\n",
      "Feature FFD_a2: Mean correlation = 0.0768\n",
      "Feature FFD_b1: Mean correlation = 0.0542\n",
      "Feature FFD_b2: Mean correlation = 0.0760\n",
      "Feature FFD_g1: Mean correlation = 0.0640\n",
      "Feature FFD_g2: Mean correlation = 0.0661\n",
      "Feature FFD_t1: Mean correlation = 0.0609\n",
      "Feature FFD_t2: Mean correlation = 0.0610\n",
      "Feature GD_a1: Mean correlation = 0.0799\n",
      "Feature GD_a2: Mean correlation = 0.0837\n",
      "Feature GD_b1: Mean correlation = 0.0611\n",
      "Feature GD_b2: Mean correlation = 0.0837\n",
      "Feature GD_g1: Mean correlation = 0.0672\n",
      "Feature GD_g2: Mean correlation = 0.0666\n",
      "Feature GD_t1: Mean correlation = 0.0638\n",
      "Feature GD_t2: Mean correlation = 0.0624\n",
      "Feature GPT_a1: Mean correlation = 0.0941\n",
      "Feature GPT_a2: Mean correlation = 0.0942\n",
      "Feature GPT_b1: Mean correlation = 0.0756\n",
      "Feature GPT_b2: Mean correlation = 0.1013\n",
      "Feature GPT_g1: Mean correlation = 0.0877\n",
      "Feature GPT_g2: Mean correlation = 0.0840\n",
      "Feature GPT_t1: Mean correlation = 0.0755\n",
      "Feature GPT_t2: Mean correlation = 0.0701\n",
      "Feature TRT_a1: Mean correlation = 0.0824\n",
      "Feature TRT_a2: Mean correlation = 0.0849\n",
      "Feature TRT_b1: Mean correlation = 0.0653\n",
      "Feature TRT_b2: Mean correlation = 0.0921\n",
      "Feature TRT_g1: Mean correlation = 0.0759\n",
      "Feature TRT_g2: Mean correlation = 0.0800\n",
      "Feature TRT_t1: Mean correlation = 0.0685\n",
      "Feature TRT_t2: Mean correlation = 0.0640\n",
      "Subject resultsZPH_SR: Overall mean correlation = 0.0749\n",
      "Saved all mapping results to saved_data/mapping_results.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Linear mapping with save points\n",
    "results_path = Path('saved_data/mapping_results.pkl')\n",
    "\n",
    "if results_path.exists():\n",
    "    print(f\"Loading mapping results from {results_path}\")\n",
    "    with open(results_path, 'rb') as f:\n",
    "        results_by_subject = pickle.load(f)\n",
    "else:\n",
    "    mapper = BrainEmbeddingMapper()\n",
    "    results_by_subject = {}\n",
    "    \n",
    "    for subject_id, word_data in all_subjects_data.items():\n",
    "        subject_result_path = Path(f'saved_data/subject_{subject_id}_results.pkl')\n",
    "        \n",
    "        if subject_result_path.exists():\n",
    "            with open(subject_result_path, 'rb') as f:\n",
    "                results = pickle.load(f)\n",
    "            results_by_subject[subject_id] = results\n",
    "            print(f\"Loaded results for subject {subject_id}\")\n",
    "            continue\n",
    "            \n",
    "        # Combine word data with embeddings\n",
    "        combined_data = []\n",
    "        for word in word_data:\n",
    "            sent_id = word['sentence_id']\n",
    "            word_idx = word['word_idx']\n",
    "            \n",
    "            if sent_id in sentence_embeddings and word_idx in sentence_embeddings[sent_id]:\n",
    "                combined_data.append({\n",
    "                    'word': word['word'],\n",
    "                    'sentence_id': sent_id,\n",
    "                    'word_idx': word_idx,\n",
    "                    'embedding': sentence_embeddings[sent_id][word_idx],\n",
    "                    'eeg_features': word['eeg_features']\n",
    "                })\n",
    "        \n",
    "        # Train linear mapping for this subject\n",
    "        # results = mapper.train_mapper(combined_data, feature_name='FFD_t1')\n",
    "        results = mapper.train_multifeature_mapper(combined_data, n_splits=5)\n",
    "        results_by_subject[subject_id] = results\n",
    "        \n",
    "        # Save subject results\n",
    "        with open(subject_result_path, 'wb') as f:\n",
    "            pickle.dump(results, f)\n",
    "        print(f\"Saved results for subject {subject_id}\")\n",
    "        \n",
    "        # Print results for this subject\n",
    "        if results:\n",
    "            # New structure is a dictionary by feature\n",
    "            feature_means = []\n",
    "            for feature, feature_results in results.items():\n",
    "                feature_mean = np.mean([fold['mean_correlation'] for fold in feature_results['results']])\n",
    "                feature_means.append(feature_mean)\n",
    "                print(f\"Feature {feature}: Mean correlation = {feature_mean:.4f}\")\n",
    "            \n",
    "            overall_mean = np.mean(feature_means)\n",
    "            print(f\"Subject {subject_id}: Overall mean correlation = {overall_mean:.4f}\")\n",
    "    \n",
    "    # Save all results\n",
    "    with open(results_path, 'wb') as f:\n",
    "        pickle.dump(results_by_subject, f)\n",
    "    print(f\"Saved all mapping results to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c4469",
   "metadata": {},
   "source": [
    "# VISUALIZE (by Subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1a507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# # Assuming results_by_subject has been loaded\n",
    "# results_path = Path('saved_data/mapping_results.pkl')\n",
    "# with open(results_path, 'rb') as f:\n",
    "#     results_by_subject = pickle.load(f)\n",
    "\n",
    "# # 1. Bar plot of mean correlation by subject\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# subject_means = {}\n",
    "# for subject_id, results in results_by_subject.items():\n",
    "#     if results:  # Check if results exist\n",
    "#         mean_corr = np.mean([fold['mean_correlation'] for fold in results])\n",
    "#         subject_means[subject_id] = mean_corr\n",
    "\n",
    "# # Sort by correlation value\n",
    "# sorted_subjects = sorted(subject_means.items(), key=lambda x: x[1], reverse=True)\n",
    "# subjects = [s[0] for s in sorted_subjects]\n",
    "# means = [s[1] for s in sorted_subjects]\n",
    "\n",
    "# plt.bar(subjects, means)\n",
    "# plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "# plt.xlabel('Subject ID')\n",
    "# plt.ylabel('Mean Correlation')\n",
    "# plt.title('Mean Correlation by Subject')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('subject_correlations.png')\n",
    "# plt.show()\n",
    "\n",
    "# # 2. Distribution of correlations across electrodes\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# all_correlations = []\n",
    "# all_subjects = []\n",
    "\n",
    "# for subject_id, results in results_by_subject.items():\n",
    "#     if results:\n",
    "#         for fold in results:\n",
    "#             all_correlations.extend(fold['correlations'])\n",
    "#             all_subjects.extend([subject_id] * len(fold['correlations']))\n",
    "\n",
    "# # Create dataframe for seaborn\n",
    "# import pandas as pd\n",
    "# corr_df = pd.DataFrame({\n",
    "#     'Correlation': all_correlations,\n",
    "#     'Subject': all_subjects\n",
    "# })\n",
    "\n",
    "# sns.violinplot(x='Subject', y='Correlation', data=corr_df)\n",
    "# plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "# plt.title('Distribution of Electrode Correlations by Subject')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('electrode_correlations.png')\n",
    "# plt.show()\n",
    "\n",
    "# # 3. Heatmap of correlations for one subject\n",
    "# # Choose the subject with highest mean correlation\n",
    "# best_subject = sorted_subjects[0][0]\n",
    "# best_results = results_by_subject[best_subject]\n",
    "\n",
    "# # Aggregate correlations across folds\n",
    "# electrode_means = np.zeros(105)  # Assuming 105 electrodes\n",
    "# for fold in best_results:\n",
    "#     for i, corr in enumerate(fold['correlations']):\n",
    "#         electrode_means[i] += corr\n",
    "# electrode_means /= len(best_results)\n",
    "\n",
    "# # Reshape to approximate head layout (simplified)\n",
    "# # Adjust these dimensions based on actual electrode layout\n",
    "# reshaped_corrs = electrode_means.reshape(15, 7)\n",
    "\n",
    "# plt.figure(figsize=(8, 12))\n",
    "# sns.heatmap(reshaped_corrs, cmap='RdBu_r', center=0, \n",
    "#             vmin=-0.3, vmax=0.3)\n",
    "# plt.title(f'Electrode Correlation Heatmap - Subject {best_subject}')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('electrode_heatmap.png')\n",
    "# plt.show()\n",
    "\n",
    "# # 4. Cross-subject consistency\n",
    "# # Create a matrix of correlations for each electrode across subjects\n",
    "# all_subject_ids = list(results_by_subject.keys())\n",
    "# electrode_by_subject = np.zeros((len(all_subject_ids), 105))\n",
    "\n",
    "# for i, subject_id in enumerate(all_subject_ids):\n",
    "#     results = results_by_subject[subject_id]\n",
    "#     if results:\n",
    "#         # Average across folds\n",
    "#         fold_means = np.zeros(105)\n",
    "#         for fold in results:\n",
    "#             for j, corr in enumerate(fold['correlations']):\n",
    "#                 fold_means[j] += corr\n",
    "#         fold_means /= len(results)\n",
    "#         electrode_by_subject[i] = fold_means\n",
    "\n",
    "# # Calculate correlation between subjects\n",
    "# subject_correlation = np.corrcoef(electrode_by_subject)\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(subject_correlation, annot=True, cmap='coolwarm', \n",
    "#             xticklabels=all_subject_ids, yticklabels=all_subject_ids)\n",
    "# plt.title('Cross-subject Consistency')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('cross_subject_consistency.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b73d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "##@title PLOTTING PARAMETERS (defaults)\n",
    "\n",
    "# Set the default font size for plots\n",
    "text_size = 20\n",
    "\n",
    "figure_width = 4 # for single column\n",
    "page_width = 8 # for two column\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': text_size,        # Base font size\n",
    "    'axes.titlesize': text_size,   # Title\n",
    "    'axes.labelsize': text_size,   # Axis labels\n",
    "    'xtick.labelsize': text_size,  # X tick labels\n",
    "    'ytick.labelsize': text_size,  # Y tick labels\n",
    "    'legend.fontsize': text_size,  # Legend\n",
    "    'figure.titlesize': text_size,  # Figure title\n",
    "    'lines.linewidth': 2.0,      # Line width\n",
    "    'lines.markersize': 3.0,     # Marker size\n",
    "})\n",
    "# Axis style (get rid of top and right)\n",
    "plt.rcParams['axes.spines.top'] = False # remove the top line\n",
    "plt.rcParams['axes.spines.right'] = False # remove the right line\n",
    "\n",
    "# No Grid\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "plt.rcParams['lines.markersize'] = 10 \n",
    "\n",
    "\n",
    "def visualize_results(results_by_subject):\n",
    "    \"\"\"Visualize results from our mapping approach\"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path('visualizations')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Prepare data\n",
    "    data = []\n",
    "    \n",
    "    for subject_id, subject_results in results_by_subject.items():\n",
    "        # Handle the case where results is a list of fold results (original mapper)\n",
    "        if isinstance(subject_results, list):\n",
    "            feature = 'FFD_t1'  # Default feature name\n",
    "            for fold_idx, fold in enumerate(subject_results):\n",
    "                mean_corr = fold['mean_correlation']\n",
    "                for i, corr in enumerate(fold['correlations']):\n",
    "                    data.append({\n",
    "                        'Subject': subject_id,\n",
    "                        'Feature': feature,\n",
    "                        'Fold': fold_idx,\n",
    "                        'Electrode': i,\n",
    "                        'Correlation': corr\n",
    "                    })\n",
    "        # Handle dictionary of features (multi-feature mapper)\n",
    "        elif isinstance(subject_results, dict):\n",
    "            for feature, feature_data in subject_results.items():\n",
    "                if 'results' in feature_data:\n",
    "                    for fold_idx, fold in enumerate(feature_data['results']):\n",
    "                        mean_corr = fold['mean_correlation']\n",
    "                        for i, corr in enumerate(fold['correlations']):\n",
    "                            data.append({\n",
    "                                'Subject': subject_id,\n",
    "                                'Feature': feature,\n",
    "                                'Fold': fold_idx,\n",
    "                                'Electrode': i,\n",
    "                                'Correlation': corr\n",
    "                            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Subject performance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    subject_means = df.groupby('Subject')['Correlation'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    plt.bar(subject_means.index, subject_means.values)\n",
    "    plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "    plt.xlabel('Subject ID')\n",
    "    plt.ylabel('Mean Correlation')\n",
    "    plt.title('Mean Correlation by Subject')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'subject_correlations.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # If multiple features are present\n",
    "    if len(df['Feature'].unique()) > 1:\n",
    "        # Feature performance\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        feature_means = df.groupby('Feature')['Correlation'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        plt.bar(feature_means.index, feature_means.values)\n",
    "        plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "        plt.xlabel('EEG Feature')\n",
    "        plt.ylabel('Mean Correlation')\n",
    "        plt.title('Mean Correlation by EEG Feature')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'feature_correlations.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Distribution of correlations across electrodes\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.violinplot(x='Subject', y='Correlation', data=df)\n",
    "    plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "    plt.title('Distribution of Electrode Correlations by Subject')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'electrode_correlations.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Cross-subject consistency\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    subjects = sorted(df['Subject'].unique())\n",
    "    corr_matrix = np.zeros((len(subjects), len(subjects)))\n",
    "    np.fill_diagonal(corr_matrix, 1.0)  # Self-correlation = 1\n",
    "    \n",
    "    for i, subj1 in enumerate(subjects):\n",
    "        for j, subj2 in enumerate(subjects):\n",
    "            if i < j:  # Only calculate once for each pair\n",
    "                s1 = df[df['Subject'] == subj1].groupby('Electrode')['Correlation'].mean()\n",
    "                s2 = df[df['Subject'] == subj2].groupby('Electrode')['Correlation'].mean()\n",
    "                \n",
    "                # Find common electrodes\n",
    "                common_elec = list(set(s1.index) & set(s2.index))\n",
    "                if common_elec:\n",
    "                    corr = np.corrcoef(s1[common_elec], s2[common_elec])[0, 1]\n",
    "                    corr_matrix[i, j] = corr\n",
    "                    corr_matrix[j, i] = corr  # Matrix is symmetric\n",
    "    \n",
    "    sns.heatmap(corr_matrix, xticklabels=subjects, yticklabels=subjects, \n",
    "               cmap='coolwarm', vmin=-1, vmax=1, annot=True, fmt='.2f')\n",
    "    plt.title('Cross-subject Consistency')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'subject_consistency.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0909673",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_data = visualize_results(results_by_subject)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8928b31",
   "metadata": {},
   "source": [
    "# steering (with eeg features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c61e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_steering_vector(embedding_model, text, steering_vector, scale=1.0):\n",
    "    # Check if steering vector is None\n",
    "    if steering_vector is None:\n",
    "        print(\"Warning: Steering vector is None. Proceeding without steering.\")\n",
    "        # Just run the model normally without hooks\n",
    "        return embedding_model(text)\n",
    "    \n",
    "    # Define the hook function\n",
    "    def steering_hook(acts, hook):\n",
    "        # Apply to final layer activations\n",
    "        if acts.shape[-1] == len(steering_vector):\n",
    "            # Project activations onto steering direction and amplify\n",
    "            projection = torch.matmul(\n",
    "                acts, \n",
    "                torch.tensor(steering_vector, dtype=acts.dtype, device=acts.device)\n",
    "            )\n",
    "            \n",
    "            # Apply steering by adding scaled projection\n",
    "            return acts + scale * projection.unsqueeze(-1) * torch.tensor(\n",
    "                steering_vector, dtype=acts.dtype, device=acts.device\n",
    "            )\n",
    "        return acts\n",
    "    \n",
    "    # Run model with hook\n",
    "    output = embedding_model.run_with_hooks(\n",
    "        text,\n",
    "        fwd_hooks=[(\"blocks.23.hook_resid_post\", steering_hook)]\n",
    "    )\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def generate_with_steering(model, prompt, steering_vector, scale=1.0, max_new_tokens=20):\n",
    "    \"\"\"Generate text with a steering vector applied during generation\"\"\"\n",
    "    \n",
    "    # Define the hook function\n",
    "    def steering_hook(acts, hook):\n",
    "        # Apply to final layer activations\n",
    "        if acts.shape[-1] == len(steering_vector):\n",
    "            # Project activations onto steering direction and amplify\n",
    "            projection = torch.matmul(\n",
    "                acts, \n",
    "                torch.tensor(steering_vector, dtype=acts.dtype, device=acts.device)\n",
    "            )\n",
    "            \n",
    "            # Apply steering by adding scaled projection\n",
    "            return acts + scale * projection.unsqueeze(-1) * torch.tensor(\n",
    "                steering_vector, dtype=acts.dtype, device=acts.device\n",
    "            )\n",
    "        return acts\n",
    "    \n",
    "    # Run model with hook for generation\n",
    "    output = model.generate(\n",
    "        prompt, \n",
    "        max_new_tokens=max_new_tokens,\n",
    "        fwd_hooks=[(\"blocks.23.hook_resid_post\", steering_hook)]\n",
    "    )\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f7124a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_steering_vector(mapper, results_by_subject, embedding_gen):\n",
    "    # Check the models dictionary\n",
    "    if hasattr(mapper, 'models') and isinstance(mapper.models, dict):\n",
    "        print(f\"Available features: {list(mapper.models.keys())}\")\n",
    "        \n",
    "        # Try to extract steering vector for a standard feature\n",
    "        feature_name = \"FFD_t1\"  # Standard feature to try\n",
    "        print(f\"Attempting to extract steering vector for feature: {feature_name}\")\n",
    "        \n",
    "        # Extract steering vector using the existing method\n",
    "        steering_vector = mapper.extract_steering_vector(\n",
    "            feature_name=feature_name,\n",
    "            method='weighted',\n",
    "            threshold=0.1\n",
    "        )\n",
    "        \n",
    "        if steering_vector is None:\n",
    "            print(f\"Failed to extract steering vector for feature {feature_name}\")\n",
    "            return None\n",
    "        \n",
    "        # Test the steering vector\n",
    "        print(f\"Testing with: 'The experiment results indicated that'\")\n",
    "        sentence = \"The experiment results indicated that\"\n",
    "        \n",
    "        # Generate without steering for comparison\n",
    "        original_output = embedding_gen.model.generate(sentence, max_new_tokens=20)\n",
    "        print(f\"Original: {original_output}\")\n",
    "        \n",
    "        return steering_vector\n",
    "    else:\n",
    "        print(\"Mapper does not have expected 'models' attribute\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def test_steering_vectors(mapper, embedding_gen):\n",
    "    \"\"\"Test steering vectors on various prompts\"\"\"\n",
    "    \n",
    "    # Get a feature for steering\n",
    "    feature_name = \"FFD_t1\"  # First fixation duration, theta band\n",
    "    \n",
    "    # Extract steering vector\n",
    "    steering_vector = mapper.extract_steering_vector(\n",
    "        feature_name=feature_name,\n",
    "        method='weighted',\n",
    "        threshold=0.1\n",
    "    )\n",
    "    \n",
    "    if steering_vector is None:\n",
    "        print(f\"Failed to extract steering vector for feature {feature_name}\")\n",
    "        return\n",
    "    \n",
    "    # Test prompts\n",
    "    test_prompts = [\n",
    "        \"The experiment results indicated that\",\n",
    "        \"The brain activity during reading showed\",\n",
    "        \"Analysis of the EEG data revealed\"\n",
    "    ]\n",
    "    \n",
    "    # Test with different steering scales\n",
    "    for prompt in test_prompts:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        \n",
    "        # Without steering\n",
    "        print(\"No steering:\")\n",
    "        text = generate_with_steering(\n",
    "            embedding_gen.model, prompt, steering_vector, scale=0.0)\n",
    "        print(text)\n",
    "        \n",
    "        # With different steering scales\n",
    "        for scale in [0.5, 1.0, 2.0]:\n",
    "            print(f\"\\nSteering with scale={scale}:\")\n",
    "            text = generate_with_steering(\n",
    "                embedding_gen.model, prompt, steering_vector, scale=scale)\n",
    "            print(text)\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*50)\n",
    "    \n",
    "def compare_feature_steering(mapper, embedding_gen):\n",
    "    \"\"\"Compare steering vectors from different EEG features\"\"\"\n",
    "    \n",
    "    # List of features to compare\n",
    "    features = [\n",
    "        \"FFD_t1\",  # First fixation duration, theta band\n",
    "        \"FFD_a1\",  # First fixation duration, alpha band\n",
    "        \"FFD_g1\",  # First fixation duration, gamma band\n",
    "        \"TRT_t1\",  # Total reading time, theta band\n",
    "    ]\n",
    "    \n",
    "    # Extract steering vectors\n",
    "    vectors = {}\n",
    "    for feature in features:\n",
    "        vector = mapper.extract_steering_vector(\n",
    "            feature_name=feature,\n",
    "            method='weighted',\n",
    "            threshold=0.1\n",
    "        )\n",
    "        if vector is not None:\n",
    "            vectors[feature] = vector\n",
    "    \n",
    "    if not vectors:\n",
    "        print(\"Failed to extract any steering vectors\")\n",
    "        return\n",
    "    \n",
    "    # Test prompt\n",
    "    prompt = \"The neural activity recorded in this experiment\"\n",
    "    \n",
    "    # Generate without steering\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(\"\\nNo steering:\")\n",
    "    text = generate_with_steering(\n",
    "        embedding_gen.model, prompt, next(iter(vectors.values())), scale=0.0)\n",
    "    print(text)\n",
    "    \n",
    "    # Compare different features with the same scale\n",
    "    scale = 1.0\n",
    "    for feature, vector in vectors.items():\n",
    "        print(f\"\\nSteering with {feature} (scale={scale}):\")\n",
    "        text = generate_with_steering(\n",
    "            embedding_gen.model, prompt, vector, scale=scale)\n",
    "        print(text)\n",
    "\n",
    "def generate_with_steering(model, prompt, steering_vector, scale=1.0, max_new_tokens=20):\n",
    "    \"\"\"Generate text with a steering vector applied during generation\"\"\"\n",
    "    \n",
    "    # Define the hook function\n",
    "    def steering_hook(acts, hook):\n",
    "        # Apply to final layer activations\n",
    "        if acts.shape[-1] == len(steering_vector):\n",
    "            # Project activations onto steering direction and amplify\n",
    "            projection = torch.matmul(\n",
    "                acts, \n",
    "                torch.tensor(steering_vector, dtype=acts.dtype, device=acts.device)\n",
    "            )\n",
    "            \n",
    "            # Apply steering by adding scaled projection\n",
    "            return acts + scale * projection.unsqueeze(-1) * torch.tensor(\n",
    "                steering_vector, dtype=acts.dtype, device=acts.device\n",
    "            )\n",
    "        return acts\n",
    "    \n",
    "    # TransformerLens uses a context manager for hooks during generation\n",
    "    with model.hooks(fwd_hooks=[(\"blocks.23.hook_resid_post\", steering_hook)]):\n",
    "        output = model.generate(prompt, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d983456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: The experiment results indicated that\n",
      "No steering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment results indicated that training increased acute rewarding effects (i.e., desensitization); thus, training activations\n",
      "\n",
      "Steering with scale=0.5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment results indicated that horizontal frequency-restricted survival differed according to whether cellular swelling was induced by 2D laser filtering via N\n",
      "\n",
      "Steering with scale=1.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment results indicated that 75 million teens admitted to trouble with alcohol, drugs or alcohol use were 15 to 18 years old.\n",
      "\n",
      "Steering with scale=2.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment results indicated that young women who wear short dreadlocks remain attractive even if they are the same height and weight as their\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: The brain activity during reading showed\n",
      "No steering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brain activity during reading showed a temporal pattern of decreased brain activity during intact mothers with no expressive behavior or as children. A further\n",
      "\n",
      "Steering with scale=0.5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brain activity during reading showed signs of improvement upon leaving the location of the septum and emerged brighter than the area when watching\n",
      "\n",
      "Steering with scale=1.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brain activity during reading showed that the first pages of each e-book was considered more intense than when reading separate volumes of the\n",
      "\n",
      "Steering with scale=2.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brain activity during reading showed clear peak in the dorsolateral prefrontal cortex (DLPFC), indicate increased activation, compared to\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Prompt: Analysis of the EEG data revealed\n",
      "No steering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of the EEG data revealed that the EEG had remarkably consistent before pulses and after pulses. All the fields were fully diurnal,\n",
      "\n",
      "Steering with scale=0.5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of the EEG data revealed that the authors again gave rise to a dolphin eating something after the feast. This was an indication of\n",
      "\n",
      "Steering with scale=1.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of the EEG data revealed changes that appeared to be significant and related to the projectors. Importantly, spectroscopic analysis\n",
      "\n",
      "Steering with scale=2.0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of the EEG data revealed a tension between the activity in the PCRM and the subthalamic nucleus (STN), which\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_steering_vectors(mapper, embedding_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0c7cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ef852a5",
   "metadata": {},
   "source": [
    "# sentiment steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30daee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direct_sentiment_vector(embedding_gen):\n",
    "    \"\"\"Extract sentiment vector directly from language model\"\"\"\n",
    "    # Define positive and negative examples\n",
    "    positive_examples = [\"happy\", \"joy\", \"excellent\", \"wonderful\", \"fantastic\"]\n",
    "    negative_examples = [\"sad\", \"terrible\", \"awful\", \"horrible\", \"disappointing\"]\n",
    "    \n",
    "    # Get embeddings\n",
    "    pos_embeds = []\n",
    "    for word in positive_examples:\n",
    "        _, cache = embedding_gen.model.run_with_cache(word)\n",
    "        embed = cache['blocks.23.hook_resid_post'][0, -1].detach().cpu().numpy()\n",
    "        pos_embeds.append(embed)\n",
    "    \n",
    "    neg_embeds = []\n",
    "    for word in negative_examples:\n",
    "        _, cache = embedding_gen.model.run_with_cache(word)\n",
    "        embed = cache['blocks.23.hook_resid_post'][0, -1].detach().cpu().numpy()\n",
    "        neg_embeds.append(embed)\n",
    "    \n",
    "    # Average embeddings\n",
    "    pos_centroid = np.mean(pos_embeds, axis=0)\n",
    "    neg_centroid = np.mean(neg_embeds, axis=0)\n",
    "    \n",
    "    # Sentiment vector\n",
    "    sentiment_vector = pos_centroid - neg_centroid\n",
    "    sentiment_vector = sentiment_vector / np.linalg.norm(sentiment_vector)\n",
    "    \n",
    "    return sentiment_vector\n",
    "\n",
    "def test_sentiment_steering(embedding_gen):\n",
    "    # Get sentiment vector\n",
    "    sentiment_vector = get_direct_sentiment_vector(embedding_gen)\n",
    "    \n",
    "    # Test prompts\n",
    "    test_prompts = [\n",
    "        \"The story was\", \n",
    "        \"The experience was\", \n",
    "        \"The movie made me feel\"\n",
    "    ]\n",
    "    \n",
    "    for prompt in test_prompts:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        \n",
    "        # Without steering\n",
    "        print(\"No steering:\")\n",
    "        text = generate_with_steering(embedding_gen.model, prompt, sentiment_vector, scale=0.0)\n",
    "        print(text)\n",
    "        \n",
    "        # With positive steering\n",
    "        for scale in [1.0, 2.0, 4.0]:\n",
    "            print(f\"\\nPositive steering (scale={scale}):\")\n",
    "            text = generate_with_steering(embedding_gen.model, prompt, sentiment_vector, scale=scale)\n",
    "            print(text)\n",
    "        \n",
    "        # With negative steering\n",
    "        for scale in [1.0, 2.0, 4.0]:\n",
    "            print(f\"\\nNegative steering (scale={scale}):\")\n",
    "            text = generate_with_steering(embedding_gen.model, prompt, -sentiment_vector, scale=scale)\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2afc79b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: The story was\n",
      "No steering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story was told about how my laptop instructor went furnitureless, had the storage device fall off the front side,\n",
      "\n",
      "Positive steering (scale=1.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story was fast becoming known. At around of 1pm on April 22, 2012, shortly before the report was\n",
      "\n",
      "Positive steering (scale=2.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story was another distraction in a voracious Democrat-crafted media campaign to discredit the president at every turn,\n",
      "\n",
      "Positive steering (scale=4.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story was broken well by PLOS Quest member Joelle Walker, who wrote a short blog post describing a paper\n",
      "\n",
      "Negative steering (scale=1.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story was one of impact and uncertainty. The news of technology's advance was mostly greeted with equal celebration.\n",
      "\n",
      "\n",
      "Negative steering (scale=2.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story was about how a young girl runs away from home to live a way, a space free from violence.\n",
      "\n",
      "Negative steering (scale=4.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story was told not by a lecherous historian, but by a favorite among patriots — he was honored\n",
      "\n",
      "Prompt: The experience was\n",
      "No steering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experience was much more uplifting. It was my first time feeling isolated with charities. I was so in charge\n",
      "\n",
      "Positive steering (scale=1.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experience was completely new to him. Vanver was sure his frustration had reached the point of being infectious.\n",
      "\n",
      "\n",
      "Positive steering (scale=2.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experience was part of a four-symposium at Boston University on Friday titled \"Enhancing Responsive Design and\n",
      "\n",
      "Positive steering (scale=4.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experience was adventurous and fun. Somehow discovering it was fun. Traveling was great. Wanting to get inside\n",
      "\n",
      "Negative steering (scale=1.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experience was like an adventure. There were horseflies everywhere and all the time. I was frozen in place in\n",
      "\n",
      "Negative steering (scale=2.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experience was perhaps one of the greatest battles between rival MMO campaigns ever seen. It started with solid records scoring in\n",
      "\n",
      "Negative steering (scale=4.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experience was surreal. For months now, I've been working on the Kickstarter project, printed on exquisite soft tissue\n",
      "\n",
      "Prompt: The movie made me feel\n",
      "No steering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie made me feel guilty for declining a slice with a large glass of beer, but I pretty much understood all of my\n",
      "\n",
      "Positive steering (scale=1.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie made me feel out of sorts. The characters expressed a shocking sentiment. I felt unworthy of them. I felt like\n",
      "\n",
      "Positive steering (scale=2.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie made me feel depressed, despondent, helpless and all those triggering emotions, but most enjoyable I guess…\n",
      "\n",
      "\n",
      "Positive steering (scale=4.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie made me feel appreciated because it determined someone's psyche and made sure nothing more startling would happen, sacrificing padding pairs and\n",
      "\n",
      "Negative steering (scale=1.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie made me feel like a 13-, 14-year-old boy, and I assembled on this page to experience it\n",
      "\n",
      "Negative steering (scale=2.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie made me feel worthless and uninteresting. I didn't have 'what it takes' and nostalgia may or may not\n",
      "\n",
      "Negative steering (scale=4.0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 13.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie made me feel like this is a metaphor for how things get done these days in the real world: Tresdin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentiment_steering(embedding_gen)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fc3a5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 positive and 0 negative samples\n",
      "Not enough brain activity data found\n",
      "\n",
      "Prompt: The story was\n",
      "No steering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# Without steering\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo steering:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m text = \u001b[43mgenerate_with_steering\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_gen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# With positive steering\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 143\u001b[39m, in \u001b[36mgenerate_with_steering\u001b[39m\u001b[34m(model, prompt, steering_vector, scale, max_new_tokens)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# TransformerLens uses a context manager for hooks during generation\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m model.hooks(fwd_hooks=[(\u001b[33m\"\u001b[39m\u001b[33mblocks.23.hook_resid_post\u001b[39m\u001b[33m\"\u001b[39m, steering_hook)]):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:2261\u001b[39m, in \u001b[36mHookedTransformer.generate\u001b[39m\u001b[34m(self, input, max_new_tokens, stop_at_eos, eos_token_id, do_sample, top_k, top_p, temperature, freq_penalty, use_past_kv_cache, prepend_bos, padding_side, return_type, verbose)\u001b[39m\n\u001b[32m   2251\u001b[39m         logits = \u001b[38;5;28mself\u001b[39m.forward(\n\u001b[32m   2252\u001b[39m             residual[:, -\u001b[32m1\u001b[39m:],\n\u001b[32m   2253\u001b[39m             return_type=\u001b[33m\"\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2258\u001b[39m             shortformer_pos_embed=shortformer_pos_embed,\n\u001b[32m   2259\u001b[39m         )\n\u001b[32m   2260\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2261\u001b[39m         logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2262\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2263\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogits\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2264\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2265\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2266\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2267\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstart_at_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_at_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2268\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2269\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2270\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2271\u001b[39m     \u001b[38;5;66;03m# We input the entire sequence, as a [batch, pos] tensor, since we aren't using\u001b[39;00m\n\u001b[32m   2272\u001b[39m     \u001b[38;5;66;03m# the cache.\u001b[39;00m\n\u001b[32m   2273\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.forward(\n\u001b[32m   2274\u001b[39m         residual,\n\u001b[32m   2275\u001b[39m         return_type=\u001b[33m\"\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2279\u001b[39m         shortformer_pos_embed=shortformer_pos_embed,\n\u001b[32m   2280\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:612\u001b[39m, in \u001b[36mHookedTransformer.forward\u001b[39m\u001b[34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[39m\n\u001b[32m    607\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    608\u001b[39m         shortformer_pos_embed = shortformer_pos_embed.to(\n\u001b[32m    609\u001b[39m             devices.get_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m.cfg)\n\u001b[32m    610\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m     residual = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    622\u001b[39m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/transformer_lens/components/transformer_block.py:187\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[39m\n\u001b[32m    185\u001b[39m     normalized_resid_mid = \u001b[38;5;28mself\u001b[39m.ln2(mlp_in)\n\u001b[32m    186\u001b[39m     mlp_out = \u001b[38;5;28mself\u001b[39m.apply_mlp(normalized_resid_mid)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     resid_post = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhook_resid_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresid_mid\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_out\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.parallel_attn_mlp:\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# Dumb thing done by GPT-J, both MLP and Attn read from resid_pre and write to resid_post, no resid_mid used.\u001b[39;00m\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# In GPT-J, LN1 and LN2 are tied, in GPT-NeoX they aren't.\u001b[39;00m\n\u001b[32m    191\u001b[39m     normalized_resid_pre_2 = \u001b[38;5;28mself\u001b[39m.ln2(\n\u001b[32m    192\u001b[39m         resid_pre \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.use_hook_mlp_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hook_mlp_in(resid_pre.clone())\n\u001b[32m    193\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1850\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1806\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1804\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1805\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1806\u001b[39m     hook_result = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1808\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1809\u001b[39m     result = hook_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/AISC2025_Zuco2LLM/.conda/lib/python3.11/site-packages/transformer_lens/hook_points.py:109\u001b[39m, in \u001b[36mHookPoint.add_hook.<locals>.full_hook\u001b[39m\u001b[34m(module, module_input, module_output)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mdir\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mbwd\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m ):  \u001b[38;5;66;03m# For a backwards hook, module_output is a tuple of (grad,) - I don't know why.\u001b[39;00m\n\u001b[32m    108\u001b[39m     module_output = module_output[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 128\u001b[39m, in \u001b[36mgenerate_with_steering.<locals>.steering_hook\u001b[39m\u001b[34m(acts, hook)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msteering_hook\u001b[39m(acts, hook):\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# Apply to final layer activations\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m acts.shape[-\u001b[32m1\u001b[39m] == \u001b[38;5;28mlen\u001b[39m(steering_vector):\n\u001b[32m    129\u001b[39m         \u001b[38;5;66;03m# Project activations onto steering direction and amplify\u001b[39;00m\n\u001b[32m    130\u001b[39m         projection = torch.matmul(\n\u001b[32m    131\u001b[39m             acts, \n\u001b[32m    132\u001b[39m             torch.tensor(steering_vector, dtype=acts.dtype, device=acts.device)\n\u001b[32m    133\u001b[39m         )\n\u001b[32m    135\u001b[39m         \u001b[38;5;66;03m# Apply steering by adding scaled projection\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "sentiment_csv_path = Path('sentiment_labels_cleaned.csv')\n",
    "\n",
    "def get_brain_derived_sentiment_vector(mapper, all_subjects_data, sentiment_labels_path=sentiment_csv_path):\n",
    "    \"\"\"Extract sentiment vector using brain-to-LLM mapping with labeled sentences\"\"\"\n",
    "    # Load sentiment labels\n",
    "    import pandas as pd\n",
    "    sentiment_df = pd.read_csv(sentiment_labels_path)\n",
    "    \n",
    "    # Choose a subject with good mapping results\n",
    "    subject_id = 'resultsZJS_SR'  # Replace with best-performing subject\n",
    "    \n",
    "    # Select a brain feature that mapped well\n",
    "    feature_name = 'GPT_g2'  # Or best feature based on mapping results\n",
    "    \n",
    "    # Get the model from mapper\n",
    "    model_data = mapper.models[feature_name]\n",
    "    model = model_data['model']\n",
    "    \n",
    "    # Get words from positive and negative sentences\n",
    "    pos_brain_activity = []\n",
    "    neg_brain_activity = []\n",
    "    \n",
    "    words_data = all_subjects_data[subject_id]\n",
    "    \n",
    "    for word_item in words_data:\n",
    "        sent_id = word_item['sentence_id']\n",
    "        \n",
    "        # Find sentiment for this sentence\n",
    "        sent_match = sentiment_df[sentiment_df['sentence_id'] == sent_id]\n",
    "        if not sent_match.empty:\n",
    "            sentiment = sent_match['sentiment'].values[0]\n",
    "            \n",
    "            if sentiment > 0 and feature_name in word_item['eeg_features']:\n",
    "                feature = word_item['eeg_features'][feature_name]\n",
    "                if hasattr(feature, 'shape') and not np.isnan(feature).any():\n",
    "                    pos_brain_activity.append(feature)\n",
    "            elif sentiment < 0 and feature_name in word_item['eeg_features']:\n",
    "                feature = word_item['eeg_features'][feature_name]\n",
    "                if hasattr(feature, 'shape') and not np.isnan(feature).any():\n",
    "                    neg_brain_activity.append(feature)\n",
    "    \n",
    "    print(f\"Found {len(pos_brain_activity)} positive and {len(neg_brain_activity)} negative samples\")\n",
    "    \n",
    "    # Average brain activity\n",
    "    if len(pos_brain_activity) < 10 or len(neg_brain_activity) < 10:\n",
    "        print(\"Not enough brain activity data found\")\n",
    "        return None\n",
    "        \n",
    "    pos_brain = np.mean(pos_brain_activity, axis=0)\n",
    "    neg_brain = np.mean(neg_brain_activity, axis=0)\n",
    "    \n",
    "    # Get the sentiment vector in brain space\n",
    "    brain_sentiment_vector = pos_brain - neg_brain\n",
    "    \n",
    "    # Use the mapping to project to LLM space\n",
    "    llm_sentiment_vector = model.coef_.T @ brain_sentiment_vector\n",
    "    \n",
    "    # Normalize\n",
    "    llm_sentiment_vector = llm_sentiment_vector / np.linalg.norm(llm_sentiment_vector)\n",
    "    \n",
    "    return llm_sentiment_vector\n",
    "\n",
    "# Usage:\n",
    "sentiment_vector = get_brain_derived_sentiment_vector(mapper, all_subjects_data)\n",
    "\n",
    "# Test steering with the vector\n",
    "test_prompts = [\"The story was\", \"The experience was\", \"The movie made me feel\"]\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    \n",
    "    # Without steering\n",
    "    print(\"No steering:\")\n",
    "    text = generate_with_steering(embedding_gen.model, prompt, sentiment_vector, scale=0.0)\n",
    "    print(text)\n",
    "    \n",
    "    # With positive steering\n",
    "    for scale in [1.0, 2.0, 4.0]:\n",
    "        print(f\"\\nPositive steering (scale={scale}):\")\n",
    "        text = generate_with_steering(embedding_gen.model, prompt, sentiment_vector, scale=scale)\n",
    "        print(text)\n",
    "    \n",
    "    # With negative steering\n",
    "    for scale in [1.0, 2.0, 4.0]:\n",
    "        print(f\"\\nNegative steering (scale={scale}):\")\n",
    "        text = generate_with_steering(embedding_gen.model, prompt, -sentiment_vector, scale=scale)\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class SentimentSteeringExtractor:\n",
    "#     def __init__(self, data_loader, embedding_generator, sentiment_path=sentiment_csv_path):\n",
    "#         self.data_loader = data_loader\n",
    "#         self.embedding_generator = embedding_generator\n",
    "#         self.sentiment_data = self._load_sentiment_data(sentiment_path)\n",
    "        \n",
    "#     def _load_sentiment_data(self, path):\n",
    "#         # Load sentiment labels from CSV file\n",
    "#         import pandas as pd\n",
    "#         try:\n",
    "#             return pd.read_csv(path)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading sentiment data: {e}\")\n",
    "#             return None\n",
    "            \n",
    "#     def extract_sentiment_vectors(self, subject_id):\n",
    "#         \"\"\"Extract sentiment vectors from EEG data\"\"\"\n",
    "#         # Get EEG data for this subject\n",
    "#         word_data = self.data_loader.extract_word_level_data(subject_id)\n",
    "        \n",
    "#         # Group words by sentiment\n",
    "#         positive_words = []\n",
    "#         negative_words = []\n",
    "        \n",
    "#         for word in word_data:\n",
    "#             # Match with sentiment data\n",
    "#             word_text = word['word']\n",
    "#             sent_id = word['sentence_id']\n",
    "            \n",
    "#             # Find sentiment for this sentence\n",
    "#             sentiment = self._get_sentiment(sent_id)\n",
    "#             if sentiment > 0:\n",
    "#                 positive_words.append(word)\n",
    "#             elif sentiment < 0:\n",
    "#                 negative_words.append(word)\n",
    "        \n",
    "#         # Compute average brain embeddings for positive and negative words\n",
    "#         positive_embedding = self._compute_brain_embedding(positive_words)\n",
    "#         negative_embedding = self._compute_brain_embedding(negative_words)\n",
    "        \n",
    "#         # Compute sentiment direction as the difference\n",
    "#         sentiment_vector = positive_embedding - negative_embedding\n",
    "        \n",
    "#         # Normalize\n",
    "#         sentiment_vector = sentiment_vector / np.linalg.norm(sentiment_vector)\n",
    "        \n",
    "#         return sentiment_vector\n",
    "        \n",
    "#     def _get_sentiment(self, sentence_id):\n",
    "#         \"\"\"Get sentiment label for a sentence\"\"\"\n",
    "#         if self.sentiment_data is None:\n",
    "#             return 0\n",
    "            \n",
    "#         # Find sentiment for this sentence ID\n",
    "#         try:\n",
    "#             sent_row = self.sentiment_data[self.sentiment_data['sentence_id'] == sentence_id]\n",
    "#             if not sent_row.empty:\n",
    "#                 return sent_row['sentiment'].values[0]\n",
    "#         except:\n",
    "#             pass\n",
    "#         return 0\n",
    "    \n",
    "#     def _compute_brain_embedding(self, words):\n",
    "#         \"\"\"Compute average brain embedding from EEG features\"\"\"\n",
    "#         # Initialize embedding\n",
    "#         feature_name = 'FFD_t1'  # Using first fixation duration, theta band\n",
    "        \n",
    "#         all_features = []\n",
    "#         for word in words:\n",
    "#             if feature_name in word['eeg_features']:\n",
    "#                 feature = word['eeg_features'][feature_name]\n",
    "#                 if hasattr(feature, 'shape') and not np.isnan(feature).any():\n",
    "#                     all_features.append(feature)\n",
    "        \n",
    "#         if not all_features:\n",
    "#             return None\n",
    "            \n",
    "#         # Average across all words\n",
    "#         brain_embedding = np.mean(all_features, axis=0)\n",
    "#         return brain_embedding\n",
    "    \n",
    "#     def map_to_model_space(self, brain_vector, mapper):\n",
    "#         \"\"\"Map brain vector to model embedding space\"\"\"\n",
    "#         if brain_vector is None:\n",
    "#             return None\n",
    "            \n",
    "#         # Use trained mapper to convert brain vector to model space\n",
    "#         if not hasattr(mapper, 'models') or not mapper.models:\n",
    "#             print(\"No trained models available\")\n",
    "#             return None\n",
    "            \n",
    "#         # Get a trained model (using first available feature)\n",
    "#         feature_name = next(iter(mapper.models.keys()))\n",
    "#         model_data = mapper.models[feature_name]\n",
    "        \n",
    "#         if not isinstance(model_data, dict) or 'model' not in model_data:\n",
    "#             print(\"Invalid model format\")\n",
    "#             return None\n",
    "            \n",
    "#         # Extract model\n",
    "#         model = model_data['model']\n",
    "        \n",
    "#         # Map brain vector to model space using inverse mapping\n",
    "#         # This is an approximation - actual mapping would depend on model type\n",
    "#         try:\n",
    "#             # For Ridge regression, we can use the coefficients directly\n",
    "#             model_vector = model.coef_.T @ brain_vector\n",
    "            \n",
    "#             # Normalize\n",
    "#             model_vector = model_vector / np.linalg.norm(model_vector)\n",
    "#             return model_vector\n",
    "#         except:\n",
    "#             print(\"Failed to map brain vector to model space\")\n",
    "#             return None\n",
    "\n",
    "# def test_sentiment_steering(subject_id, data_loader, embedding_gen, mapper):\n",
    "#     \"\"\"Test sentiment steering for a subject\"\"\"\n",
    "    \n",
    "#     # Extract sentiment vector\n",
    "#     extractor = SentimentSteeringExtractor(data_loader, embedding_gen)\n",
    "#     sentiment_brain_vector = extractor.extract_sentiment_vectors(subject_id)\n",
    "    \n",
    "#     if sentiment_brain_vector is None:\n",
    "#         print(\"Failed to extract sentiment vector\")\n",
    "#         return\n",
    "        \n",
    "#     # Map to model space\n",
    "#     sentiment_model_vector = extractor.map_to_model_space(sentiment_brain_vector, mapper)\n",
    "    \n",
    "#     if sentiment_model_vector is None:\n",
    "#         print(\"Failed to map sentiment vector to model space\")\n",
    "#         return\n",
    "    \n",
    "#     # Test prompts\n",
    "#     test_prompts = [\n",
    "#         \"The story was\",\n",
    "#         \"The movie made me feel\",\n",
    "#         \"Reading this book was an experience that was\"\n",
    "#     ]\n",
    "    \n",
    "#     # Test with different steering scales\n",
    "#     for prompt in test_prompts:\n",
    "#         print(f\"\\nPrompt: {prompt}\")\n",
    "        \n",
    "#         # Without steering\n",
    "#         print(\"No steering:\")\n",
    "#         text = generate_with_steering(\n",
    "#             embedding_gen.model, prompt, sentiment_model_vector, scale=0.0)\n",
    "#         print(text)\n",
    "        \n",
    "#         # With positive steering (sentiment vector)\n",
    "#         for scale in [1.0, 2.0]:\n",
    "#             print(f\"\\nPositive steering (scale={scale}):\")\n",
    "#             text = generate_with_steering(\n",
    "#                 embedding_gen.model, prompt, sentiment_model_vector, scale=scale)\n",
    "#             print(text)\n",
    "            \n",
    "#         # With negative steering (negative sentiment vector)\n",
    "#         for scale in [1.0, 2.0]:\n",
    "#             print(f\"\\nNegative steering (scale={scale}):\")\n",
    "#             text = generate_with_steering(\n",
    "#                 embedding_gen.model, prompt, -sentiment_model_vector, scale=scale)\n",
    "#             print(text)\n",
    "        \n",
    "#         print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9ce9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00101be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading sentiment data: Error tokenizing data. C error: Expected 3 fields in line 28, saw 4\n",
      "\n",
      "Loading data from ../zuco_data/zuco1.0/task1-SR/Matlab files/resultsZJS_SR.mat\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m extractor = SentimentSteeringExtractor(zuco_loader, embedding_gen)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Extract sentiment vector and map to model space\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m sentiment_brain_vector = \u001b[43mextractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_sentiment_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m sentiment_model_vector = extractor.map_to_model_space(sentiment_brain_vector, mapper)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Test sentiment steering\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mSentimentSteeringExtractor.extract_sentiment_vectors\u001b[39m\u001b[34m(self, subject_id)\u001b[39m\n\u001b[32m     41\u001b[39m negative_embedding = \u001b[38;5;28mself\u001b[39m._compute_brain_embedding(negative_words)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Compute sentiment direction as the difference\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m sentiment_vector = \u001b[43mpositive_embedding\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_embedding\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Normalize\u001b[39;00m\n\u001b[32m     47\u001b[39m sentiment_vector = sentiment_vector / np.linalg.norm(sentiment_vector)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# # Initialize the extraction and create steering vector\n",
    "# subject_id = 'resultsZJS_SR'  # Choose a subject\n",
    "# extractor = SentimentSteeringExtractor(zuco_loader, embedding_gen)\n",
    "\n",
    "# # Extract sentiment vector and map to model space\n",
    "# sentiment_brain_vector = extractor.extract_sentiment_vectors(subject_id)\n",
    "# sentiment_model_vector = extractor.map_to_model_space(sentiment_brain_vector, mapper)\n",
    "\n",
    "# # Test sentiment steering\n",
    "# test_sentiment_steering(subject_id, zuco_loader, embedding_gen, mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae9fcc",
   "metadata": {},
   "source": [
    "# cross subject steering (todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_steering_vector(self, feature_name='FFD_t1', method='weighted', threshold=0.1):\n",
    "#     \"\"\"\n",
    "#     Extract a steering vector using different methods:\n",
    "#     - 'weighted': Weight electrodes by correlation strength\n",
    "#     - 'top_n': Use only top N electrodes \n",
    "#     - 'threshold': Use electrodes with correlation above threshold\n",
    "#     \"\"\"\n",
    "#     if feature_name not in self.models:\n",
    "#         print(f\"No model trained for feature {feature_name}\")\n",
    "#         return None\n",
    "        \n",
    "#     feature_data = self.models[feature_name]\n",
    "    \n",
    "#     # Handle both single-feature and multi-feature formats\n",
    "#     if isinstance(feature_data, dict) and 'model' in feature_data:\n",
    "#         model = feature_data['model']\n",
    "#         results = feature_data['results']\n",
    "#     else:\n",
    "#         model = feature_data  # Original format\n",
    "#         results = self.models[feature_name]['results']\n",
    "    \n",
    "#     weights = model.coef_.T  # [embedding_dim, n_electrodes]\n",
    "    \n",
    "#     # Calculate correlation strength per electrode\n",
    "#     correlation_means = []\n",
    "#     for result in results:\n",
    "#         correlation_means.append(np.array(result['correlations']))\n",
    "#     electrode_correlations = np.mean(np.stack(correlation_means), axis=0)\n",
    "    \n",
    "#     # Select electrodes based on method\n",
    "#     if method == 'weighted':\n",
    "#         # Weight each electrode by its correlation strength\n",
    "#         electrode_weights = np.abs(electrode_correlations)\n",
    "#         electrode_weights = electrode_weights / np.sum(electrode_weights)\n",
    "#         steering_vector = np.zeros(weights.shape[0])\n",
    "        \n",
    "#         for i, weight in enumerate(electrode_weights):\n",
    "#             if not np.isnan(weight):\n",
    "#                 steering_vector += weight * weights[:, i]\n",
    "                \n",
    "#     elif method == 'top_n':\n",
    "#         n_electrodes = 10  # Default to top 10\n",
    "#         # Get top N electrodes by absolute correlation\n",
    "#         top_indices = np.argsort(np.abs(electrode_correlations))[-n_electrodes:]\n",
    "#         steering_vector = np.mean(weights[:, top_indices], axis=1)\n",
    "        \n",
    "#     elif method == 'threshold':\n",
    "#         # Use electrodes above correlation threshold\n",
    "#         mask = np.abs(electrode_correlations) > threshold\n",
    "#         if not np.any(mask):\n",
    "#             print(f\"No electrodes above threshold {threshold}\")\n",
    "#             return None\n",
    "#         steering_vector = np.mean(weights[:, mask], axis=1)\n",
    "    \n",
    "#     else:\n",
    "#         raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "#     # Normalize\n",
    "#     steering_vector = steering_vector / np.linalg.norm(steering_vector)\n",
    "#     return steering_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af348500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacb4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
